\begin{figure}[htbp]
\centering
\includegraphics{jflex-black.png}
\caption{}
\end{figure}

Copyright © 1998--2015 by \href{http://www.doclsf.de}{Gerwin Klein},
Steve Rowe, and Régis Décamps.

Version 1.7.0-SNAPSHOT, 16 March 2015

\section{Introduction}\label{Intro}

JFlex is a lexical analyser generator for Java\footnote{Java is a
  trademark of Sun Microsystems, Inc., and refers to Sun's Java
  programming language. JFlex is not sponsored by or affiliated with Sun
  Microsystems, Inc.} written in Java. It is also a rewrite of the tool
JLex \autocite{JLex} which was developed by Elliot Berk at Princeton
University. As Vern Paxson states for his C/C++ tool flex
\autocite{flex}: they do not share any code though.

\subsection{Design goals}\label{design-goals}

The main design goals of JFlex are:

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  \textbf{Full unicode support}
\item
  \textbf{Fast generated scanners}
\item
  \textbf{Fast scanner generation}
\item
  \textbf{Convenient specification syntax}
\item
  \textbf{Platform independence}
\item
  \textbf{JLex compatibility}
\end{itemize}

\subsection{About this manual}\label{about-this-manual}

This manual gives a brief but complete description of the tool JFlex. It
assumes that you are familiar with the topic of lexical analysis in
parsing. The references \textcite{Aho_SU_86} and \textcite{Appel_98}
provide a good introduction.

The next section of this manual describes
\hyperref[Installing]{installation procedures} for JFlex.
\hyperref[Example]{Working with JFlex - an example} runs through an
example specification and explains how it works. The section on
\hyperref[Specifications]{Lexical specifications} presents all JFlex
options and the complete specification syntax;
\hyperref[sec:encodings]{Encodings, Platforms, and Unicode} provides
information about Unicode and scanning text vs.~binary files.
\hyperref[performance]{A few words on performance} gives tips on how to
write fast scanners. The section on \hyperref[Porting]{porting scanners}
shows how to port scanners from JLex, and from the \texttt{lex} and
\texttt{flex} tools for C. Finally, \hyperref[WorkingTog]{working
together} discusses interfacing JFlex scanners with the LALR parser
generators CUP, CUP2, BYacc/J, Jay.

\hyperdef{}{Installing}{\section{Installing and Running
JFlex}\label{Installing}}

\subsection{Installing JFlex}\label{installing-jflex}

\subsubsection{Windows}\label{windows}

To install JFlex on Windows, follow these three steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\itemsep1pt\parskip0pt\parsep0pt
\item
  Unzip the file you downloaded into the directory you want JFlex in. If
  you unzipped it to say \texttt{C:\textbackslash{}}, the following
  directory structure should be generated:
\end{enumerate}

\begin{verbatim}
    C:\jflex-1.6.1\ 
        +--bin\                        (start scripts) 
        +--doc\                        (FAQ and manual) 
        +--examples\ 
            +--byaccj\                 (calculator example for BYacc/J) 
            +--cup\                    (calculator example for cup) 
            +--interpreter\            (interpreter example for cup) 
            +--java\                   (Java lexer specification) 
            +--simple-maven\           (example scanner built with maven) 
            +--standalone-maven\       (a simple standalone scanner, 
                                        built with maven) 
            +--zero-reader\            (Readers that return 0 characters) 
        +--lib\                        (precompiled classes, skeleton files) 
        +--src\ 
            +--main\ 
                +--cup\                (JFlex parser spec) 
                +--java\ 
                    +--java_cup\ 
                        +--runtime\    (source code of cup runtime classes) 
                    +--jflex\          (source code of JFlex) 
                        +--gui\        (source code of JFlex UI classes) 
                +--jflex\              (JFlex scanner spec) 
                +--resources\          (messages and default skeleton file) 
            +--test\                   (unit tests)
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\item
  Edit the file \textbf{\texttt{bin\textbackslash{}jflex.bat}} (in the
  example it's
  \texttt{C:\textbackslash{}jflex-1.6.1\textbackslash{}bin\textbackslash{}jflex.bat})
  such that

  \begin{itemize}
  \item
    \textbf{\texttt{JAVA\_HOME}} contains the directory where your Java
    JDK is installed (for instance \texttt{C:\textbackslash{}java}) and
  \item
    \textbf{\texttt{JFLEX\_HOME}} the directory that contains JFlex (in
    the example: \texttt{C:\textbackslash{}jflex-1.6.1})
  \end{itemize}
\item
  Include the \texttt{bin\textbackslash{}} directory of JFlex in your
  path. (the one that contains the start script, in the example:
  \texttt{C:\textbackslash{}jflex-1.6.1bin}).
\end{enumerate}

\subsubsection{Mac/Unix with tar}\label{macunix-with-tar}

To install JFlex on a Mac or Unix system, follow these two steps:

\begin{itemize}
\item
  Decompress the archive into a directory of your choice with GNU tar,
  for instance to \texttt{/usr/share}:

  \texttt{tar\ -C\ /usr/share\ -xvzf\ jflex-1.6.1.tar.gz}

  (The example is for site wide installation. You need to be root for
  that. User installation works exactly the same way --- just choose a
  directory where you have write permission)
\item
  Make a symbolic link from somewhere in your binary path to
  \texttt{bin/jflex}, for instance:

  \texttt{ln\ -s\ /usr/share/jflex-1.6.1/bin/jflex\ /usr/bin/jflex}

  If the Java interpreter is not in your binary path, you need to supply
  its location in the script \texttt{bin/jflex}.
\end{itemize}

You can verify the integrity of the downloaded file with the SHA1
checksum available on the \href{http://jflex.de/download.html}{JFlex
download page}. If you put the checksum file in the same directory as
the archive, and run:

\texttt{shasum\ -\/-check\ jflex-1.6.1.tar.gz.sha1}

it should tell you

\texttt{jflex-1.6.1.tar.gz:\ OK}

\subsection{Running JFlex}\label{running-jflex}

You run JFlex with:

\texttt{jflex\ \textless{}options\textgreater{}\ \textless{}inputfiles\textgreater{}}

It is also possible to skip the start script in \texttt{bin/} and
include the file \texttt{lib/jflex-1.6.1.jar} in your \texttt{CLASSPATH}
environment variable instead.

Then you run JFlex with:

\texttt{java\ jflex.Main\ \textless{}options\textgreater{}\ \textless{}inputfiles\textgreater{}}

or with:

\texttt{java\ -jar\ jflex-1.6.1.jar\ \textless{}options\textgreater{}\ \textless{}inputfiles\textgreater{}}

The input files and options are in both cases optional. If you don't
provide a file name on the command line, JFlex will pop up a window to
ask you for one.

JFlex knows about the following options:

\texttt{-d\ \textless{}directory\textgreater{}}\\writes the generated
file to the directory \texttt{\textless{}directory\textgreater{}}

\texttt{-\/-skel\ \textless{}file\textgreater{}}\\uses external skeleton
\texttt{\textless{}file\textgreater{}}. This is mainly for JFlex
maintenance and special low level customisations. Use only when you know
what you are doing! JFlex comes with a skeleton file in the \texttt{src}
directory that reflects exactly the internal, pre-compiled skeleton and
can be used with the \texttt{-skel} option.

\texttt{-\/-nomin}\\skip the DFA minimisation step during scanner
generation.

\texttt{-\/-jlex}\\tries even harder to comply to JLex interpretation of
specs.

\texttt{-\/-dot}\\generate graphviz dot files for the NFA, DFA and
minimised DFA. This feature is still in alpha status, and not fully
implemented yet.

\texttt{-\/-dump}\\display transition tables of NFA, initial DFA, and
minimised DFA

\texttt{-\/-legacydot}\\dot (\texttt{.}) meta character matches
\texttt{{[}\^{}\textbackslash{}n{]}} instead
of\\\texttt{{[}\^{}\textbackslash{}n\textbackslash{}r\textbackslash{}u000B\textbackslash{}u000C\textbackslash{}u0085\textbackslash{}u2028\textbackslash{}u2029{]}}

\texttt{-\/-noinputstreamctor}\\don't include an InputStream constructor
in the generated scanner

\texttt{-\/-verbose} or \texttt{-v}\\display generation progress
messages (enabled by default)

\texttt{-\/-quiet} or \texttt{-q}\\display error messages only (no
chatter about what JFlex is currently doing)

\texttt{-\/-warn-unused}\\warn about unused macros (by default true in
verbose mode and false in quiet mode)

\texttt{-\/-no-warn-unused}\\do not warn about unused macros (by default
true in verbose mode and false in quiet mode)

\texttt{-\/-time}\\display time statistics about the code generation
process (not very accurate)

\texttt{-\/-version}\\print version number

\texttt{-\/-info}\\print system and JDK information (useful if you'd
like to report a problem)

\texttt{-\/-unicodever\ \textless{}ver\textgreater{}}\\print all
supported properties for Unicode version
\texttt{\textless{}ver\textgreater{}}

\texttt{-\/-help} or \texttt{-h}\\print a help message explaining
options and usage of JFlex.

\hyperdef{}{Example}{\section{A simple Example: How to work with
JFlex}\label{Example}}

To demonstrate how a lexical specification with JFlex looks like, this
section presents a part of the specification for the Java language. The
example does not describe the whole lexical structure of Java programs,
but only a small and simplified part of it (some keywords, some
operators, comments and only two kinds of literals). It also shows how
to interface with the LALR parser generator CUP \autocite{CUP} and
therefore uses a class \texttt{sym} (generated by CUP), where integer
constants for the terminal tokens of the CUP grammar are declared. JFlex
comes with a directory \texttt{examples}, where you can find a small
standalone scanner that doesn't need other tools like CUP to give you
working example code without dependencies.

The \texttt{examples} directory also contains a \emph{complete} JFlex
specification of the lexical structure of Java programs together with
the CUP parser specification for Java by C. Scott Ananian, obtained from
the CUP \autocite{CUP} web site (modified to interface with the JFlex
scanner). Both specifications adhere to the Java Language Specification
\autocite{LangSpec}.

\begin{verbatim}
    /* JFlex example: partial Java language lexer specification */
    import java_cup.runtime.*;

    /**
     * This class is a simple example lexer.
     */
    %%

    %class Lexer
    %unicode
    %cup
    %line
    %column

    %{
      StringBuffer string = new StringBuffer();

      private Symbol symbol(int type) {
        return new Symbol(type, yyline, yycolumn);
      }
      private Symbol symbol(int type, Object value) {
        return new Symbol(type, yyline, yycolumn, value);
      }
    %}

    LineTerminator = \r|\n|\r\n
    InputCharacter = [^\r\n]
    WhiteSpace     = {LineTerminator} | [ \t\f]

    /* comments */
    Comment = {TraditionalComment} | {EndOfLineComment} | {DocumentationComment}

    TraditionalComment   = "/*" [^*] ~"*/" | "/*" "*"+ "/"
    // Comment can be the last line of the file, without line terminator.
    EndOfLineComment     = "//" {InputCharacter}* {LineTerminator}?
    DocumentationComment = "/**" {CommentContent} "*"+ "/"
    CommentContent       = ( [^*] | \*+ [^/*] )*

    Identifier = [:jletter:] [:jletterdigit:]*

    DecIntegerLiteral = 0 | [1-9][0-9]*

    %state STRING

    %%

    /* keywords */
    <YYINITIAL> "abstract"           { return symbol(sym.ABSTRACT); }
    <YYINITIAL> "boolean"            { return symbol(sym.BOOLEAN); }
    <YYINITIAL> "break"              { return symbol(sym.BREAK); }

    <YYINITIAL> {
      /* identifiers */ 
      {Identifier}                   { return symbol(sym.IDENTIFIER); }
     
      /* literals */
      {DecIntegerLiteral}            { return symbol(sym.INTEGER_LITERAL); }
      \"                             { string.setLength(0); yybegin(STRING); }

      /* operators */
      "="                            { return symbol(sym.EQ); }
      "=="                           { return symbol(sym.EQEQ); }
      "+"                            { return symbol(sym.PLUS); }

      /* comments */
      {Comment}                      { /* ignore */ }
     
      /* whitespace */
      {WhiteSpace}                   { /* ignore */ }
    }

    <STRING> {
      \"                             { yybegin(YYINITIAL); 
                                       return symbol(sym.STRING_LITERAL, 
                                       string.toString()); }
      [^\n\r\"\\]+                   { string.append( yytext() ); }
      \\t                            { string.append('\t'); }
      \\n                            { string.append('\n'); }

      \\r                            { string.append('\r'); }
      \\\"                           { string.append('\"'); }
      \\                             { string.append('\\'); }
    }

    /* error fallback */
    [^]                              { throw new Error("Illegal character <"+
                                                        yytext()+">"); }
\end{verbatim}

From this specification JFlex generates a \texttt{.java} file with one
class that contains code for the scanner. The class will have a
constructor taking a \texttt{java.io.Reader} from which the input is
read. The class will also have a function \texttt{yylex()} that runs the
scanner and that can be used to get the next token from the input (in
this example the function actually has the name \texttt{next\_token()}
because the specification uses the \texttt{\%cup} switch).

As with JLex, the specification consists of three parts, divided by
\texttt{\%\%}:

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  \hyperref[ExampleUserCode]{usercode},
\item
  \hyperref[ExampleOptions]{options and declarations} and
\item
  \hyperref[ExampleLexRules]{lexical rules}.
\end{itemize}

\hyperdef{}{ExampleUserCode}{\subsection{Code to
include}\label{ExampleUserCode}}

Let's take a look at the first section, \emph{user code}: The text up to
the first line starting with \texttt{\%\%} is copied verbatim to the top
of the generated lexer class (before the actual class declaration). Next
to \texttt{package} and \texttt{import} statements there is usually not
much to do here. If the code ends with a \texttt{javadoc} class comment,
the generated class will get this comment, if not, JFlex will generate
one automatically.

\hyperdef{}{ExampleOptions}{\subsection{Options and
Macros}\label{ExampleOptions}}

The second section \emph{options and declarations} is more interesting.
It consists of a set of options, code that is included inside the
generated scanner class, lexical states and macro declarations. Each
JFlex option must begin a line of the specification and starts with a
\texttt{\%}. In our example the following options are used:

\begin{itemize}
\item
  \texttt{\%class\ Lexer} tells JFlex to give the generated class the
  name \texttt{Lexer} and to write the code to a file
  \texttt{Lexer.java}.
\item
  \texttt{\%unicode} defines the set of characters the scanner will work
  on. For scanning text files, \texttt{\%unicode} should always be used.
  The Unicode version may be specified, e.g. \texttt{\%unicode\ 4.1}. If
  no version is specified, the most recent supported Unicode version
  will be used - in JFlex 1.7.0-SNAPSHOT, this is Unicode 7.0. See also
  \hyperref[sec:encodings]{Encodings} for more information on character
  sets, encodings, and scanning text vs.~binary files.
\item
  \texttt{\%cup} switches to CUP compatibility mode to interface with a
  CUP generated parser.
\item
  \texttt{\%line} switches line counting on (the current line number can
  be accessed via the variable \texttt{yyline})
\item
  \texttt{\%column} switches column counting on (the current column is
  accessed via \texttt{yycolumn})
\end{itemize}

The code between \texttt{\%\{} and \texttt{\%\}} is copied verbatim into
the generated lexer class source. Here you can declare member variables
and functions that are used inside scanner actions. In our example we
declare a \texttt{StringBuffer} \texttt{string} in which we will store
parts of string literals and two helper functions \texttt{symbol} that
create \texttt{java\_cup.runtime.Symbol} objects with position
information of the current token (see also \hyperref[CUPWork]{JFlex and
CUP} for how to interface with the parser generator CUP). As with all
JFlex options, both \texttt{\%\{} and \texttt{\%\}} must begin a line.

The specification continues with macro declarations. Macros are
abbreviations for regular expressions, used to make lexical
specifications easier to read and understand. A macro declaration
consists of a macro identifier followed by \texttt{=}, then followed by
the regular expression it represents. This regular expression may itself
contain macro usages. Although this allows a grammar-like specification
style, macros are still just abbreviations and not non-terminals -- they
cannot be recursive. Cycles in macro definitions are detected and
reported at generation time by JFlex.

Here some of the example macros in more detail:

\begin{itemize}
\item
  \texttt{LineTerminator} stands for the regular expression that matches
  an ASCII \texttt{CR}, an ASCII \texttt{LF} or a \texttt{CR} followed
  by \texttt{LF}.
\item
  \texttt{InputCharacter} stands for all characters that are not a
  \texttt{CR} or \texttt{LF}.
\item
  \texttt{TraditionalComment} is the expression that matches the string
  \texttt{/*} followed by a character that is not a \texttt{*}, followed
  by anything that does not contain, but ends in \texttt{*/}. As this
  would not match comments like \texttt{/****/}, we add \texttt{/*}
  followed by an arbitrary number (at least one) of \texttt{*} followed
  by the closing \texttt{/}. This is not the only, but one of the
  simpler expressions matching non-nesting Java comments. It is tempting
  to just write something like the expression \texttt{/*\ .*\ */}, but
  this would match more than we want. It would for instance match the
  entire input \texttt{/*\ */\ x\ =\ 0;\ /*\ */}, instead of two
  comments and four real tokens. See the macros
  \texttt{DocumentationComment} and \texttt{CommentContent} for an
  alternative.
\item
  \texttt{CommentContent} matches zero or more occurrences of any
  character except a \texttt{*} or any number of \texttt{*} followed by
  a character that is not a \texttt{/}
\item
  \texttt{Identifier} matches each string that starts with a character
  of class \texttt{jletter} followed by zero or more characters of class
  \texttt{jletterdigit}. \texttt{jletter} and \texttt{jletterdigit} are
  predefined character classes. \texttt{jletter} includes all characters
  for which the Java function \texttt{Character.isJavaIdentifierStart}
  returns \texttt{true} and \texttt{jletterdigit} all characters for
  that \texttt{Character.isJavaIdentifierPart} returns \texttt{true}.
\end{itemize}

The last part of the second section in our lexical specification is a
lexical state declaration: \texttt{state\ STRING} declares a lexical
state \texttt{STRING} that can be used in the \emph{lexical rules} part
of the specification. A state declaration is a line starting with
\texttt{\%state} followed by a space or comma separated list of state
identifiers. There can be more than one line starting with
\texttt{\%state}.

\hyperdef{}{ExampleLexRules}{\subsection{Rules and
Actions}\label{ExampleLexRules}}

The \emph{lexical rules} section of a JFlex specification contains
regular expressions and actions (Java code) that are executed when the
scanner matches the associated regular expression. As the scanner reads
its input, it keeps track of all regular expressions and activates the
action of the expression that has the longest match. Our specification
above for instance would with input \texttt{breaker} match the regular
expression for \texttt{Identifier} and not the keyword \texttt{break}
followed by the Identifier \texttt{er}, because rule
\texttt{\{Identifier\}} matches more of this input at once than any
other rule in the specification. If two regular expressions both have
the longest match for a certain input, the scanner chooses the action of
the expression that appears first in the specification. In that way, we
get for input \texttt{break} the keyword \texttt{break} and not an
Identifier \texttt{break}.

In addition to regular expression matches, one can use lexical states to
refine a specification. A lexical state acts like a start condition. If
the scanner is in lexical state \texttt{STRING}, only expressions that
are preceded by the start condition
\texttt{\textless{}STRING\textgreater{}} can be matched. A start
condition of a regular expression can contain more than one lexical
state. It is then matched when the lexer is in any of these lexical
states. The lexical state \texttt{YYINITIAL} is predefined and is also
the state in which the lexer begins scanning. If a regular expression
has no start conditions it is matched in \emph{all} lexical states.

Since there often are sets of expressions with the same start
conditions, they can be grouped:

\begin{verbatim}
<STRING> {
  expr1   { action1 }
  expr2   { action2 }
}
\end{verbatim}

means that both \texttt{expr1} and \texttt{expr2} have start condition
\texttt{\textless{}STRING\textgreater{}}.

The first three rules in our example demonstrate the syntax of a regular
expression preceded by the start condition
\texttt{\textless{}YYINITIAL\textgreater{}}.

\begin{verbatim}
<YYINITIAL> "abstract"           { return symbol(sym.ABSTRACT); }
\end{verbatim}

matches the input \texttt{abstract} only if the scanner is in its start
state \texttt{YYINITIAL}. When the string \texttt{abstract} is matched,
the scanner function returns the CUP symbol \texttt{sym.ABSTRACT}. If an
action does not return a value, the scanning process is resumed
immediately after executing the action.

The rules enclosed in

\begin{verbatim}
<YYINITIAL> { ...
\end{verbatim}

demonstrate the abbreviated syntax and are also only matched in state
\texttt{YYINITIAL}.

Of these rules, one is of special interest:

\begin{verbatim}
\"  { string.setLength(0); yybegin(STRING); }
\end{verbatim}

If the scanner matches a double quote in state \texttt{YYINITIAL} we
have recognised the start of a string literal. Therefore we clear our
\texttt{StringBuffer} that will hold the content of this string literal
and tell the scanner with \texttt{yybegin(STRING)} to switch into the
lexical state \texttt{STRING}. Because we do not yet return a value to
the parser, our scanner proceeds immediately.

In lexical state \texttt{STRING} another rule demonstrates how to refer
to the input that has been matched:

\begin{verbatim}
[^\n\r\"]+  { string.append( yytext() ); }
\end{verbatim}

The expression
\texttt{{[}\^{}\textbackslash{}n\textbackslash{}r\textbackslash{}"{]}+}
matches all characters in the input up to the next backslash (indicating
an escape sequence such as \texttt{\textbackslash{}n}), double quote
(indicating the end of the string), or line terminator (which must not
occur in a Java string literal). The matched region of the input is
referred to by \texttt{yytext()} and appended to the content of the
string literal parsed so far.

The last lexical rule in the example specification is used as an error
fallback. It matches any character in any state that has not been
matched by another rule. It doesn't conflict with any other rule because
it has the least priority (because it's the last rule) and because it
matches only one character (so it can't have longest match precedence
over any other rule).

\subsection{How to get it building}\label{how-to-get-it-building}

\begin{itemize}
\item
  \hyperref[Installing]{Install JFlex}
\item
  If you have written your specification file (or chosen one from the
  \texttt{examples} directory), save it (say under the name
  \texttt{java-lang.flex}).
\item
  Run JFlex with

  \texttt{jflex\ java-lang.flex}
\item
  JFlex should then show progress messages about generating the scanner
  and write the generated code to the directory of your specification
  file.
\item
  Compile the generated \texttt{.java} file and your own classes. (If
  you use CUP, generate your parser classes first)
\item
  That's it.
\end{itemize}

\hyperdef{}{Specifications}{\section{Lexical
Specifications}\label{Specifications}}

As shown above, a lexical specification file for JFlex consists of three
parts divided by a single line starting with \texttt{\%\%}:

\begin{verbatim}
UserCode
%%
Options and declarations
%%
Lexical rules
\end{verbatim}

In all parts of the specification comments of the form
\texttt{/*\ comment\ text\ */} and Java-style end-of-line comments
starting with \texttt{//} are permitted. JFlex comments do nest - so the
number of \texttt{/*} and \texttt{*/} should be balanced.

\subsection{User code}\label{user-code}

The first part contains user code that is copied verbatim to the
beginning of the generated source file before the scanner class
declaration. As shown in the example spec, this is the place to put
\texttt{package} declarations and \texttt{import} statements. It is
possible, but not considered good Java style to put helper classes, such
as token classes, into this section; they are usually better declared in
their own \texttt{.java} files.

\subsection{Options and declarations}\label{options-and-declarations}

The second part of the lexical specification contains options and
directives to customise the generated lexer, declarations of
\hyperref[StateDecl]{lexical states} and \hyperref[MacroDefs]{macro
definitions}.

Each JFlex directive must sit at the beginning of a line and starts with
the \texttt{\%} character. Directives that have one or more parameters
are described as follows.

\begin{verbatim}
%class "classname"
\end{verbatim}

means that you start a line with \texttt{\%class} followed by a space
followed by the name of the class for the generated scanner (the double
quotes are \emph{not} to be entered, see also the
\hyperref[Example]{example specification}).

\subsubsection{Class options and user class code}\label{ClassOptions}

These options regard name, constructor, API, and related parts of the
generated scanner class.

\begin{itemize}
\item
  \texttt{\%class\ "classname"}

  Tells JFlex to give the generated class the name \texttt{classname}
  and to write the generated code to a file \texttt{classname.java}. If
  the \texttt{-d\ \textless{}directory\textgreater{}} command line
  option is not used, the code will be written to the directory where
  the specification file resides. If no \texttt{\%class} directive is
  present in the specification, the generated class will get the name
  \texttt{Yylex} and will be written to a file \texttt{Yylex.java}.
  There should be only one \texttt{\%class} directive in a
  specification.
\item
  \texttt{\%implements\ "interface\ 1"{[},\ "interface\ 2",\ ..{]}}

  Makes the generated class implement the specified interfaces. If more
  than one \texttt{\%implements} directive is present, all specified
  interfaces will be implemented.
\item
  \texttt{\%extends\ "classname"}

  Makes the generated class a subclass of the class \texttt{classname}.
  There should be only one \texttt{\%extends} directive in a
  specification.
\item
  \texttt{\%public}

  Makes the generated class public (the class is only accessible in its
  own package by default).
\item
  \texttt{\%final}

  Makes the generated class final.
\item
  \texttt{\%abstract}

  Makes the generated class abstract.
\item
  \texttt{\%apiprivate}

  Makes all generated methods and fields of the class private.
  Exceptions are the constructor, user code in the specification, and,
  if \texttt{\%cup} is present, the method \texttt{next\_token}. All
  occurrences of \texttt{public} (one space character before and after
  \texttt{public}) in the skeleton file are replaced by \texttt{private}
  (even if a user-specified skeleton is used). Access to the generated
  class is expected to be mediated by user class code (see next switch).
\item
  \texttt{\%\{}\\\texttt{...}\\\texttt{\%\}}

  The code enclosed in \texttt{\%\{} and \texttt{\%\}} is copied
  verbatim into the generated class. Here you can define your own member
  variables and functions in the generated scanner. Like all options,
  both \texttt{\%\{} and \texttt{\%\}} must start a line in the
  specification. If more than one class code directive
  \texttt{\%\{...\%\}} is present, the code is concatenated in order of
  appearance in the specification.
\item
  \texttt{\%init\{}\\\texttt{...}\\\texttt{\%init\}}

  The code enclosed in \texttt{\%init\{} and \texttt{\%init\}} is copied
  verbatim into the constructor of the generated class. Here, member
  variables declared in the \texttt{\%\{...\%\}} directive can be
  initialised. If more than one initialiser option is present, the code
  is concatenated in order of appearance in the specification.
\item
  \texttt{\%initthrow\{}\\\texttt{"exception1"{[},\ "exception2",\ ...{]}}\\\texttt{\%initthrow\}}

  or (on a single line) just

  \texttt{\%initthrow\ "exception1"\ {[},\ "exception2",\ ...{]}}

  Causes the specified exceptions to be declared in the \texttt{throws}
  clause of the constructor. If more than one \texttt{\%initthrow\{}
  \texttt{...} \texttt{\%initthrow\}} directive is present in the
  specification, all specified exceptions will be declared.
\item
  \texttt{\%ctorarg\ "type"\ "ident"}

  Adds the specified argument to the constructors of the generated
  scanner. If more than one such directive is present, the arguments are
  added in order of occurrence in the specification. Note that this
  option conflicts with the \texttt{\%standalone} and \texttt{\%debug}
  directives, because there is no sensible default that can be created
  automatically for such parameters in the generated \texttt{main}
  methods. JFlex will warn in this case and generate an additional
  default constructor without these parameters and without user init
  code (which might potentially refer to the parameters).
\item
  \texttt{\%scanerror\ "exception"}

  Causes the generated scanner to throw an instance of the specified
  exception in case of an internal error (default is
  \texttt{java.lang.Error}). Note that this exception is only for
  internal scanner errors. With usual specifications it should never
  occur (i.e.~if there is an error fallback rule in the specification
  and only the documented scanner API is used).
\item
  \texttt{\%buffer\ "size"}

  Set the initial size of the scan buffer to the specified value
  (decimal, in bytes). The default value is 16384.
\item
  \texttt{\%include\ "filename"}

  Replaces the \texttt{\%include} verbatim by the specified file.
\end{itemize}

\subsubsection{Scanning method}\label{scanning-method}

This section shows how the scanning method can be customised. You can
redefine the name and return type of the method and it is possible to
declare exceptions that may be thrown in one of the actions of the
specification. If no return type is specified, the scanning method will
be declared as returning values of class \texttt{Yytoken}.

\begin{itemize}
\item
  \texttt{\%function\ "name"}

  Causes the scanning method to get the specified name. If no
  \texttt{\%function} directive is present in the specification, the
  scanning method gets the name \texttt{yylex}. This directive overrides
  settings of the \texttt{\%cup} switch. The default name of the
  scanning method with the \texttt{\%cup} switch is
  \texttt{next\_token}. Overriding this name might lead to the generated
  scanner being implicitly declared as \texttt{abstract}, because it
  does not provide the method \texttt{next\_token} of the interface
  \texttt{java\_cup.runtime.Scanner}. It is of course possible to
  provide a dummy implementation of that method in the class code
  section if you still want to override the function name.
\item
  \texttt{\%integer}\\\texttt{\%int}

  Both cause the scanning method to be declared as returning Java type
  \texttt{int}. Actions in the specification can then return
  \texttt{int} values as tokens. The default end of file value under
  this setting is \texttt{YYEOF}, which is a
  \texttt{public\ static\ final\ int} member of the generated class.
\item
  \texttt{\%intwrap}

  Causes the scanning method to be declared as of the Java wrapper type
  \texttt{Integer}. Actions in the specification can then return
  \texttt{Integer} values as tokens. The default end of file value under
  this setting is \texttt{null}.
\item
  \texttt{\%type\ "typename"}

  Causes the scanning method to be declared as returning values of the
  specified type. Actions in the specification can then return values of
  \texttt{typename} as tokens. The default end of file value under this
  setting is \texttt{null}. If \texttt{typename} is not a subclass of
  \texttt{java.lang.Object}, you should specify another end of file
  value using the \texttt{\%eofval\{} \texttt{...} \texttt{\%eofval\}}
  directive or the
  \hyperref[Grammar]{\texttt{\textless{}\textless{}EOF\textgreater{}\textgreater{}}
  rule}. The \texttt{\%type} directive overrides settings of the
  \texttt{\%cup} switch.
\item
  \texttt{\%yylexthrow\{}\\\texttt{"exception1"\ {[},\ "exception2",\ ...\ {]}}\\\texttt{\%yylexthrow\}}

  or, on a single line, just

  \texttt{\%yylexthrow\ "exception1"\ {[},\ "exception2",\ ...{]}}

  The exceptions listed inside \texttt{\%yylexthrow\{} \texttt{...}
  \texttt{\%yylexthrow\}} will be declared in the throws clause of the
  scanning method. If there is more than one \texttt{\%yylexthrow\{}
  \texttt{...} \texttt{\%yylexthrow\}} clause in the specification, all
  specified exceptions will be declared.
\end{itemize}

\subsubsection{The end of file}\label{the-end-of-file}

There is always a default value that the scanning method will return
when the end of file has been reached. You may however define a specific
value to return and a specific piece of code that should be executed
when the end of file is reached.

The default end of file value depends on the return type of the scanning
method:

\begin{itemize}
\item
  For \texttt{\%integer}, the scanning method will return the value
  \texttt{YYEOF}, which is a \texttt{public\ static\ final\ int} member
  of the generated class.
\item
  For \texttt{\%intwrap},
\item
  for no specified type at all, or
\item
  for a user defined type, declared using \texttt{\%type}, the value is
  \texttt{null}.
\item
  In CUP compatibility mode, using \texttt{\%cup}, the value is

  \texttt{new\ java\_cup.runtime.Symbol(sym.EOF)}
\end{itemize}

User values and code to be executed at the end of file can be defined
using these directives:

\begin{itemize}
\item
  \texttt{\%eofval\{}\\\texttt{...}\\\texttt{\%eofval\}}

  The code included in \texttt{\%eofval\{} \texttt{...}
  \texttt{\%eofval\}} will be copied verbatim into the scanning method
  and will be executed \emph{each time} the end of file is reached (more
  than once is possible when the scanning method is called again after
  the end of file has been reached). The code should return the value
  that indicates the end of file to the parser. There should be only one
  \texttt{\%eofval\{} \texttt{...} \texttt{\%eofval\}} clause in the
  specification. The \texttt{\%eofval\{\ ...\ \%eofval\}} directive
  overrides settings of the \texttt{\%cup} switch and \texttt{\%byaccj}
  switch. There is also an alternative, more readable way to specify the
  end of file value using the
  \hyperref[Grammar]{\texttt{\textless{}\textless{}EOF\textgreater{}\textgreater{}}
  rule}.
\item
  \texttt{\%eof\{}\\\texttt{...}\\\texttt{\%eof\}}

  The code included in \texttt{\%\{eof\ ...\ \%eof\}} will be executed
  exactly once, when the end of file is reached. The code is included
  inside a method \texttt{void\ yy\_do\_eof()} and should not return any
  value (use \texttt{\%eofval\{...\%eofval\}} or
  \texttt{\textless{}\textless{}EOF\textgreater{}\textgreater{}} for
  this purpose). If more than one end of file code directive is present,
  the code will be concatenated in order of appearance in the
  specification.
\item
  \texttt{\%eofthrow\{}\\\texttt{"exception1"\ {[},"exception2",\ ...\ {]}}\\\texttt{\%eofthrow\}}

  or, on a single line:

  \texttt{\%eofthrow\ "exception1"\ {[},\ "exception2",\ ...{]}}

  The exceptions listed inside \texttt{\%eofthrow\{...\%eofthrow\}} will
  be declared in the throws clause of the method \texttt{yy\_do\_eof()}.
  If there is more than one \texttt{\%eofthrow\{...\%eofthrow\}} clause
  in the specification, all specified exceptions will be declared.
\item
  \texttt{\%eofclose}

  Causes JFlex to close the input stream at the end of file. The code
  \texttt{yyclose()} is appended to the method \texttt{yy\_do\_eof()}
  (together with the code specified in \texttt{\%eof\{...\%eof\}}) and
  the exception \texttt{java.io.IOException} is declared in the throws
  clause of this method (together with those of
  \texttt{\%eofthrow\{...\%eofthrow\}})
\item
  \texttt{\%eofclose\ false}

  Turns the effect of \texttt{\%eofclose} off again (e.g.~in case
  closing of input stream is not wanted after \texttt{\%cup}).
\end{itemize}

\subsubsection{Standalone scanners}\label{standalone-scanners}

\begin{itemize}
\item
  \texttt{\%debug}

  Creates a main function in the generated class that expects the name
  of an input file on the command line and then runs the scanner on this
  input file by printing information about each returned token to the
  Java console until the end of file is reached. The information
  includes: line number (if line counting is enabled), column (if column
  counting is enabled), the matched text, and the executed action (with
  line number in the specification).
\item
  \texttt{\%standalone}

  Creates a main function in the generated class that expects the name
  of an input file on the command line and then runs the scanner on this
  input file. The values returned by the scanner are ignored, but any
  unmatched text is printed to the Java console instead. To avoid having
  to use an extra token class, the scanning method will be declared as
  having default type \texttt{int}, not \texttt{YYtoken} (if there isn't
  any other type explicitly specified). This is in most cases
  irrelevant, but could be useful to know when making another scanner
  standalone for some purpose. You should consider using the
  \texttt{\%debug} directive, if you just want to be able to run the
  scanner without a parser attached for testing etc.
\end{itemize}

\subsubsection{CUP compatibility}\label{cup-compatibility}

You may also want to read the \hyperref[CUPWork]{CUP section} if you are
interested in how to interface your generated scanner with CUP.

\begin{itemize}
\item
  \texttt{\%cup}

  The \texttt{\%cup} directive enables CUP compatibility mode and is
  equivalent to the following set of directives:

\begin{verbatim}
%implements java_cup.runtime.Scanner
%function next_token
%type java_cup.runtime.Symbol
%eofval{
  return new java_cup.runtime.Symbol(<CUPSYM>.EOF);
%eofval}
%eofclose
\end{verbatim}

  The value of \texttt{\textless{}CUPSYM\textgreater{}} defaults to
  \texttt{sym} and can be changed with the \texttt{\%cupsym} directive.
  In JLex compatibility mode (\texttt{-\/-jlex} switch on the command
  line), \texttt{\%eofclose} will not be turned on.
\item
  \texttt{\%cup2}

  The \texttt{\%cup2} directive is similar to CUP mode, just for the
  CUP2 generator from TU Munich at \url{http://www2.in.tum.de/cup2}. It
  does the following:

  \begin{itemize}
  \itemsep1pt\parskip0pt\parsep0pt
  \item
    adds CUP2 package import declarations
  \item
    implements the CUP2 scanner interface
  \item
    switches on line and column count
  \item
    sets the scanner function to \texttt{readNextTerminal}
  \item
    sets the token type to
    \texttt{ScannerToken\textless{}?\ extends\ Object\textgreater{}}
  \item
    returns the special CUP2 EOF token at end of file
  \item
    switches on unicode
  \end{itemize}
\item
  \texttt{\%cupsym\ "classname"}

  Customises the name of the CUP generated class/interface containing
  the names of terminal tokens. Default is \texttt{sym}. The directive
  should not be used after \texttt{\%cup}, only before. 
\item
  \texttt{\%cupdebug}

  Creates a main function in the generated class that expects the name
  of an input file on the command line and then runs the scanner on this
  input file. Prints line, column, matched text, and CUP symbol name for
  each returned token to standard out.
\end{itemize}

\subsubsection{BYacc/J compatibility}\label{byaccj-compatibility}

You may also want to read \hyperref[BYaccJ]{JFlex and BYacc/J} if you
are interested in how to interface your generated scanner with Byacc/J.

\begin{itemize}
\item
  \texttt{\%byacc}

  The \texttt{\%byacc} directive enables BYacc/J compatibility mode and
  is equivalent to the following set of directives:

\begin{verbatim}
%integer
%eofval{
  return 0;
%eofval}
%eofclose
\end{verbatim}
\end{itemize}

\subsubsection{Input Character sets}\label{input-character-sets}

\begin{itemize}
\item
  \texttt{\%7bit}

  Causes the generated scanner to use an 7 bit input character set
  (character codes 0-127). If an input character with a code greater
  than 127 is encountered in an input at runtime, the scanner will throw
  an \texttt{ArrayIndexOutofBoundsException}. Not only because of this,
  you should consider using the \texttt{\%unicode} directive. See also
  \hyperref[sec:encodings]{Encodings} for information about character
  encodings. This is the default in JLex compatibility mode.
\item
  \texttt{\%full}\\\texttt{\%8bit}

  Both options cause the generated scanner to use an 8 bit input
  character set (character codes 0-255). If an input character with a
  code greater than 255 is encountered in an input at runtime, the
  scanner will throw an \texttt{ArrayIndexOutofBoundsException}. Note
  that even if your platform uses only one byte per character, the
  Unicode value of a character may still be greater than 255. If you are
  scanning text files, you should consider using the \texttt{\%unicode}
  directive. See also section \hyperref[sec:encodings]{Econdings} for
  more information about character encodings.
\item
  \texttt{\%unicode}\\\texttt{\%16bit}

  Both options cause the generated scanner to use the full Unicode input
  character set, including supplementary code points: 0-0x10FFFF.
  \texttt{\%unicode} does not mean that the scanner will read two bytes
  at a time. What is read and what constitutes a character depends on
  the runtime platform. See also section
  \hyperref[sec:encodings]{Encodings} for more information about
  character encodings. This is the default unless the JLex compatibility
  mode is used (command line option \texttt{-\/-jlex}).
\item
  \texttt{\%caseless}\\\texttt{\%ignorecase}

  This option causes JFlex to handle all characters and strings in the
  specification as if they were specified in both uppercase and
  lowercase form. This enables an easy way to specify a scanner for a
  language with case insensitive keywords. The string \texttt{break} in
  a specification is for instance handled like the expression
  \texttt{{[}bB{]}{[}rR{]}{[}eE{]}{[}aA{]}{[}kK{]}}. The
  \texttt{\%caseless} option does not change the matched text and does
  not affect character classes. So \texttt{{[}a{]}} still only matches
  the character \texttt{a} and not \texttt{A}. Which letters are
  uppercase and which lowercase letters, is defined by the Unicode
  standard. In JLex compatibility mode (\texttt{-\/-jlex} switch on the
  command line), \texttt{\%caseless} and \texttt{\%ignorecase} also
  affect character classes.
\end{itemize}

\subsubsection{Line, character and column
counting}\label{line-character-and-column-counting}

\begin{itemize}
\item
  \texttt{\%char}

  Turns character counting on. The \texttt{int} member variable
  \texttt{yychar} contains the number of characters (starting with 0)
  from the beginning of input to the beginning of the current token.
\item
  \texttt{\%line}

  Turns line counting on. The \texttt{int} member variable
  \texttt{yyline} contains the number of lines (starting with 0) from
  the beginning of input to the beginning of the current token.
\item
  \texttt{\%column}

  Turns column counting on. The \texttt{int} member variable
  \texttt{yycolumn} contains the number of characters (starting with 0)
  from the beginning of the current line to the beginning of the current
  token.
\end{itemize}

\subsubsection{Obsolete JLex options}\label{obsolete-jlex-options}

\begin{itemize}
\item
  \texttt{\%notunix}

  This JLex option is obsolete in JFlex but still recognised as valid
  directive. It used to switch between Windows and Unix kind of line
  terminators (\texttt{\textbackslash{}r\textbackslash{}n} and
  \texttt{\textbackslash{}n}) for the \texttt{\$} operator in regular
  expressions. JFlex always recognises both styles of platform dependent
  line terminators.
\item
  \texttt{\%yyeof}

  This JLex option is obsolete in JFlex but still recognised as valid
  directive. In JLex it declares a public member constant
  \texttt{YYEOF}. JFlex declares it in any case.
\end{itemize}

\hyperdef{}{StateDecl}{\subsubsection{State
declarations}\label{StateDecl}}

State declarations have the following form:

\texttt{\%s{[}tate{]}\ "state\ identifier"\ {[},\ "state\ identifier",\ ...\ {]}}
for inclusive
or\\\texttt{\%x{[}state{]}\ "state\ identifier"\ {[},\ "state\ identifier",\ ...\ {]}}
for exclusive states

There may be more than one line of state declarations, each starting
with \texttt{\%state} or \texttt{\%xstate}. State identifiers are
letters followed by a sequence of letters, digits or underscores. State
identifiers can be separated by white-space or comma.

The sequence

\begin{verbatim}
%state STATE1
%xstate STATE3, XYZ, STATE_10
%state ABC STATE5
\end{verbatim}

declares the set of identifiers
\texttt{STATE1,\ STATE3,\ XYZ,\ STATE\_10,\ ABC,\ STATE5} as lexical
states, \texttt{STATE1}, \texttt{ABC}, \texttt{STATE5} as inclusive, and
\texttt{STATE3}, \texttt{XYZ}, \texttt{STATE\_10} as exclusive. See also
\hyperref[HowMatched]{How the Input is Matched} on the way lexical
states influence how the input is matched.

\hyperdef{}{MacroDefs}{\subsubsection{Macro
definitions}\label{MacroDefs}}

A macro definition has the form

\begin{verbatim}
macroidentifier = regular expression
\end{verbatim}

That means, a macro definition is a macro identifier (letter followed by
a sequence of letters, digits or underscores), that can later be used to
reference the macro, followed by optional white-space, followed by an
\texttt{=}, followed by optional white-space, followed by a regular
expression (see \hyperref[LexRules]{Lexical Rules} for more information
about the regular expression syntax).

The regular expression on the right hand side must be well formed and
must not contain the \texttt{\^{}}, \texttt{/} or \texttt{\$} operators.
\emph{Differently to JLex, macros are not just pieces of text that are
expanded by copying} - they are parsed and must be well formed.

\textbf{This is a feature.} It eliminates some very hard to find bugs in
lexical specifications (such like not having parentheses around more
complicated macros - which is not necessary with JFlex). See
\hyperref[Porting]{Porting from JLex} for more details on the problems
of JLex style macros.

Since it is allowed to have macro usages in macro definitions, it is
possible to use a grammar-like notation to specify the desired lexical
structure. However, macros remain just abbreviations of the regular
expressions they represent. They are not non-terminals of a grammar and
cannot be used recursively. JFlex detects cycles in macro definitions
and reports them at generation time. JFlex also warns you about macros
that have been defined but never used in the \emph{lexical rules}
section of the specification.

\hyperdef{}{LexRules}{\subsection{Lexical rules}\label{LexRules}}

The \emph{lexical rules} section of a JFlex specification contains a set
of regular expressions and actions (Java code) that are executed when
the scanner matches the associated regular expression.

The \texttt{\%include} directive may be used in this section to include
lexical rules from a separate file. The directive will be replaced
verbatim by the contents of the specified file.

\hyperdef{}{Grammar}{\subsubsection{Syntax}\label{Grammar}}

The syntax of the \emph{lexical rules} section is described by the
following EBNF grammar (terminal symbols are enclosed in 'quotes'):

\begin{verbatim}
LexicalRules ::= (Include|Rule)+
Include      ::= '%include' (' '|'\t'|'\b')+ File
Rule         ::= [StateList] ['^'] RegExp [LookAhead] Action 
               | [StateList] '<<EOF>>' Action
               | StateGroup 
StateGroup   ::= StateList '{' Rule+ '}' 
StateList    ::= '<' Identifier (',' Identifier)* '>' 
LookAhead    ::= '$' | '/' RegExp
Action       ::= '{' JavaCode '}' | '|'

RegExp       ::= RegExp '|' RegExp 
               | RegExp RegExp 
               | '(' RegExp ')'
               | ('!'|'~') RegExp
               | RegExp ('*'|'+'|'?')
               | RegExp "{" Number ["," Number] "}" 
               | CharClass
               | PredefinedClass 
               | MacroUsage 
               | '"' StringCharacter+ '"' 
               | Character 

CharClass    ::= '[' ['^'] CharClassContent* ']'
               | '[' ['^'] CharClassContent+ 
                     CharClassOperator CharClassContent+ ']'
                 
CharClassContent    ::= CharClass | Character |
                        Character'-'Character | 
                        MacroUsage | PredefinedClass

CharClassOperator   ::= '||' | '&&' | '--' | '~~'

MacroUsage          ::= '{' Identifier '}'

PredefinedClass     ::= '[:jletter:]' 
                      | '[:jletterdigit:]' 
                      | '[:letter:]' 
                      | '[:digit:]'
                      | '[:uppercase:]' 
                      | '[:lowercase:]'
                      | '\d' | '\D'
                      | '\s' | '\S'
                      | '\w' | '\W'
                      | '\p{' UnicodePropertySpec '}'
                      | '\P{' UnicodePropertySpec '}'
                      | '\R'
                      | '.'          
                            
UnicodePropertySpec ::= BinaryProperty | 
                        EnumeratedProperty (':' | '=') PropertyValue

BinaryProperty      ::= Identifier

EnumeratedProperty  ::= Identifier

PropertyValue       ::= Identifier
\end{verbatim}

The grammar uses the following terminal symbols:

\begin{itemize}
\item
  \texttt{File}\\a file name, either absolute or relative to the
  directory containing the lexical specification.
\item
  \texttt{JavaCode}\\a sequence of \texttt{BlockStatements} as described
  in the Java Language Specification \autocite{LangSpec}, section 14.2.
\item
  \texttt{Number}\\a non negative decimal integer.
\item
  \texttt{Identifier}\\a letter \texttt{{[}a-zA-Z{]}} followed by a
  sequence of zero or more letters, digits or underscores
  \texttt{{[}a-zA-Z0-9\_{]}}
\item
  \texttt{Character}\\an escape sequence or any unicode character that
  is not one of these meta characters:
  \texttt{\textbar{}\ \ (\ \ )\ \ \{\ \ \}\ \ {[}\ \ {]}\ \ \textless{}\ \textgreater{}\ \ \textbackslash{}\ \ .\ \ *\ \ +\ \ ?\ \ \^{}\ \ \$\ \ /\ .\ "\ \textasciitilde{}\ !}
\item
  \texttt{StringCharacter}\\an escape sequence or any unicode character
  that is not one of these meta characters:
  \texttt{\textbackslash{}\ \ "}
\item
  An escape sequence

  \begin{itemize}
  \item
    \texttt{\textbackslash{}n} \texttt{\textbackslash{}r}
    \texttt{\textbackslash{}t} \texttt{\textbackslash{}f}
    \texttt{\textbackslash{}b}
  \item
    a \texttt{\textbackslash{}x} followed by two hexadecimal digits
    \texttt{{[}a-fA-F0-9{]}} (denoting an ASCII escape sequence);
  \item
    a \texttt{\textbackslash{}u} followed by four hexadecimal digits
    \texttt{{[}a-fA-F0-9{]}}, denoting a unicode escape sequence. Note
    that these are precisely four digits, i.e.
    \texttt{\textbackslash{}u12345} is the character
    \texttt{\textbackslash{}u1234} followed by the character \texttt{5}.
  \item
    a \texttt{\textbackslash{}U} (note that the 'U' is uppercase)
    followed by six hexadecimal digits \texttt{{[}a-fA-F0-9{]}},
    denoting a unicode code point escape sequence;
  \item
    \texttt{\textbackslash{}u\{H+(\ H+)*\}}, where \texttt{H+} is one or
    more hexadecimal digits \texttt{{[}a-fA-F0-9{]}}, each \texttt{H+}
    denotes a code point - note that in character classes, only one code
    point is allowed;
  \item
    a backslash followed by a three digit octal number from 000 to 377,
    denoting an ASCII escape sequence; or
  \item
    a backslash followed by any other unicode character that stands for
    this character.
  \end{itemize}
\end{itemize}

Please note that the \texttt{\textbackslash{}n} escape sequence stands
for the ASCII LF character - not for the end of line. If you would like
to match the line terminator, you should use the expression
\texttt{\textbackslash{}r\textbar{}\textbackslash{}n\textbar{}\textbackslash{}r\textbackslash{}n}
if you want the Java conventions, or
\texttt{\textbackslash{}r\textbackslash{}n\textbar{}{[}\textbackslash{}r\textbackslash{}n\textbackslash{}u2028\textbackslash{}u2029\textbackslash{}u000B\textbackslash{}u000C\textbackslash{}u0085{]}}
(provided as predefined class \texttt{\textbackslash{}R}) if you want to
be fully Unicode compliant (see also \autocite{unicode_rep}).

The white-space characters \texttt{"\ "} (space) and
\texttt{\textbackslash{}t} (tab) can be used to improve the readability
of regular expressions. They will be ignored by JFlex. In character
classes and strings, however, white-space characters keep standing for
themselves (so the string \texttt{"\ "} still matches exactly one space
character and \texttt{{[}\ \textbackslash{}n{]}} still matches an ASCII
LF or a space character).

JFlex applies the following standard operator precedences in regular
expression (from highest to lowest):

\begin{itemize}
\item
  unary postfix operators (\texttt{*}, \texttt{+}, \texttt{?},
  \texttt{\{n\}}, \texttt{\{n,m\}})
\item
  unary prefix operators (\texttt{!}, \texttt{\textasciitilde{}})
\item
  concatenation (\texttt{RegExp::=\ RegExp\ Regexp})
\item
  union
  (\texttt{RegExp::=\ RegExp\ \textquotesingle{}\textbar{}\textquotesingle{}\ RegExp})
\end{itemize}

So the expression \texttt{a\ \textbar{}\ abc\ \textbar{}\ !cd*} for
instance is parsed as
\texttt{(a\textbar{}(abc))\ \textbar{}\ ((!c)(d*))}.

\subsubsection{Semantics}\label{Semantics}

This section gives an informal description of which text is matched by a
regular expression, i.e.~an expression described by the \texttt{RegExp}
production of the grammar \hyperref[Grammar]{above}.

A regular expression that consists solely of

\begin{itemize}
\item
  a \texttt{Character} matches this character.
\item
  a character class \texttt{{[}...{]}} matches any character in that
  class. A \texttt{Character} is considered an element of a class if it
  is listed in the class or if its code lies within a listed character
  range \texttt{Character’-’Character} or Macro or predefined character
  class. So \texttt{{[}a0-3\textbackslash{}n{]}} for instance matches
  the characters

  \texttt{a\ 0\ 1\ 2\ 3\ \textbackslash{}n}

  If the list of characters is empty (i.e.~just \texttt{{[}{]}}), the
  expression matches nothing at all (the empty set), not even the empty
  string. This can be useful in combination with the negation operator
  \texttt{!}.

  Character sets may be nested, e.g.
  \texttt{{[}{[}{[}abc{]}d{[}e{]}{]}fg{]}} is equivalent to
  \texttt{{[}abcdefg{]}}.

  Supported character set operations:

  \begin{itemize}
  \item
    Union (\texttt{\textbar{}\textbar{}}), e.g.
    \texttt{{[}{[}a-c{]}\textbar{}\textbar{}{[}d-f{]}{]}}, equivalent to
    \texttt{{[}a-cd-f{]}}: this is the default character set operation
    when no operator is specified.
  \item
    Intersection (\texttt{\&\&}), e.g.
    \texttt{{[}{[}a-f{]}\&\&{[}f-m{]}{]}}, equivalent to
    \texttt{{[}f{]}}.
  \item
    Set difference (\texttt{-\/-}), e.g. \texttt{{[}{[}a-z{]}-\/-m{]}},
    equivalent to \texttt{{[}a-ln-z{]}}.
  \item
    Symmetric difference (\texttt{\textasciitilde{}\textasciitilde{}}):
    the union of two classes minus their intersection. For instance
    \texttt{{[}\textbackslash{}p\{Letter\}\textasciitilde{}\textasciitilde{}\textbackslash{}p\{ASCII\}{]}}
    is equivalent to
    \texttt{{[}{[}\textbackslash{}p\{Letter\}\textbar{}\textbar{}\textbackslash{}p\{ASCII\}{]}-\/-}
    \texttt{{[}\textbackslash{}p\{Letter\}\&\&\textbackslash{}p\{ASCII\}{]}{]}}:
    the set of characters that are present in either
    \texttt{\textbackslash{}p\{Letter\}} or in
    \texttt{\textbackslash{}p\{ASCII\}}, but not in both.
  \end{itemize}
\item
  a negated character class
  \texttt{\textquotesingle{}{[}\^{}...{]}\textquotesingle{}} matches all
  characters not listed in the class. If the list of characters is empty
  (i.e. \texttt{{[}\^{}{]}}), the expression matches any character of
  the input character set.
\item
  a string \texttt{’’\ StringCharacter+\ ’’} matches the exact text
  enclosed in double quotes. All meta characters apart from
  \texttt{\textbackslash{}} and \texttt{"} lose their special meaning
  inside a string. See also the \texttt{\%ignorecase} switch.
\item
  a macro usage
  \texttt{\textquotesingle{}\{\textquotesingle{}\ Identifier\ \textquotesingle{}\}\textquotesingle{}}
  matches the input that is matched by the right hand side of the macro
  with name \texttt{Identifier}.
\item
  a predefined character class matches any of the characters in that
  class. There are the following predefined character classes:

  \begin{itemize}
  \item
    two predefined character classes determined by Java functions of
    class \texttt{java.lang.Character}:

\begin{verbatim}
    [:jletter:]       isJavaIdentifierStart()
    [:jletterdigit:]  isJavaIdentifierPart()
\end{verbatim}
  \item
    four predefined character classes equivalent to the following
    Unicode properties (described \hyperref[unipropsyntax]{below}):

\begin{verbatim}
    [:letter:]     \p{Letter}
    [:digit:]      \p{Digit}
    [:uppercase:]  \p{Uppercase}
    [:lowercase:]  \p{Lowercase}
\end{verbatim}
  \item
    the following meta characters, equivalent to these (sets of) Unicode
    Properties (described \hyperref[unipropsyntax]{below}):

\begin{verbatim}
    \d  \p{Digit}
    \D  \P{Digit}
    \s  \p{Whitespace}
    \S  \P{Whitespace}
    \w  [\p{Alpha}\p{Digit}\p{Mark}
         \p{Connector Punctuation}\p{Join Control}]
    \W  [^\p{Alpha}\p{Digit}\p{Mark}
          \p{Connector Punctuation}\p{Join Control}]
\end{verbatim}
  \item
    \label{unipropsyntax} Unicode Properties are character classes
    specified by each version of the Unicode Standard. JFlex supports a
    subset of all defined Properties for each supported Unicode version.
    To see the full list of supported Properties, give the
    \texttt{–uniprops\ \textless{}ver\textgreater{}} option on the JFlex
    command line, where \texttt{\textless{}ver\textgreater{}} is the
    Unicode version. Some Properties have aliases; JFlex recognizes all
    aliases for all supported properties. JFlex supports loose matching
    of Properties: case distinctions, whitespace, hyphens, and
    underscores are ignored.

    To refer to a Unicode Property, use the
    \texttt{\textbackslash{}p\{...\}} syntax, e.g.~the Greek Block can
    be referred to as \texttt{\textbackslash{}p\{Block:Greek\}}. To
    match all characters not included in a property, use the
    \texttt{\textbackslash{}P\{...\}} syntax (note that the '\texttt{P}'
    is uppercase), e.g.~to match all characters that are \textbf{not}
    letters, use \texttt{\textbackslash{}P\{Letter\}}.

    See UTS\#18 \autocite{unicode_rep} for a description of and links to
    definitions of some supported Properties. UnicodeSet
    \autocite{UnicodeSet} is an online utility to show the character
    sets corresponding to Unicode Properties and set operations on them,
    but only for the most recent Unicode version.
  \item
    Dot (\texttt{.}) matches
    \texttt{{[}\^{}\textbackslash{}r\textbackslash{}n\textbackslash{}u2028\textbackslash{}u2029\textbackslash{}u000B\textbackslash{}u000C\textbackslash{}u0085{]}}.\\Use
    the \texttt{–legacydot} option to instead match
    \texttt{{[}\^{}\textbackslash{}n{]}}.
  \item
    \texttt{\textbackslash{}R} matches any newline:
    \texttt{\textbackslash{}r\textbackslash{}n\textbar{}{[}\textbackslash{}r\textbackslash{}n\textbackslash{}u2028\textbackslash{}u2029\textbackslash{}u000B\textbackslash{}u000C\textbackslash{}u0085{]}}.
  \end{itemize}
\end{itemize}

If \texttt{a} and \texttt{b} are regular expressions, then

\begin{itemize}
\item
  \texttt{a\ \textbar{}\ b} (union)

  is the regular expression that matches all input matched by \texttt{a}
  or by \texttt{b}.
\item
  \texttt{a\ b} (concatenation)

  is the regular expression that matches the input matched by \texttt{a}
  followed by the input matched by \texttt{b}.
\item
  \texttt{a*} (Kleene closure)

  matches zero or more repetitions of the input matched by \texttt{a}
\item
  \texttt{a+} (iteration)

  is equivalent to \texttt{aa*}
\item
  \texttt{a?} (option)

  matches the empty input or the input matched by \texttt{a}
\item
  \texttt{!a} (negation)

  matches everything but the strings matched by \texttt{a}. Use with
  care: the construction of \texttt{!a} involves an additional, possibly
  exponential NFA to DFA transformation on the NFA for \texttt{a}. Note
  that with negation and union you also have (by applying DeMorgan)
  intersection and set difference: the intersection of \texttt{a} and
  \texttt{b} is \texttt{!(!a\textbar{}!b)}, the expression that matches
  everything of \texttt{a} not matched by \texttt{b} is
  \texttt{!(!a\textbar{}b)}
\item
  \texttt{\textasciitilde{}a} (upto)

  matches everything up to (and including) the first occurrence of a
  text matched by \texttt{a}. The expression \texttt{\textasciitilde{}a}
  is equivalent to \texttt{!({[}\^{}{]}*\ a\ {[}\^{}{]}*)\ a}. A
  traditional C-style comment is matched by
  \texttt{"/*"\ \textasciitilde{}"*/"}
\item
  \texttt{a\ \{n\}} (repeat)

  is equivalent to \texttt{n} times the concatenation of \texttt{a}. So
  \texttt{a\{4\}} for instance is equivalent to the expression
  \texttt{a\ a\ a\ a}. The decimal integer \texttt{n} must be positive.
\item
  \texttt{a\ \{n,m\}}

  is equivalent to at least \texttt{n} times and at most \texttt{m}
  times the concatenation of \texttt{a}. So \texttt{a\{2,4\}} for
  instance is equivalent to the expression \texttt{a\ a\ a?\ a?}. Both
  \texttt{n} and \texttt{m} are non-negative decimal integers and
  \texttt{m} must not be smaller than \texttt{n}.
\item
  \texttt{(a)}

  matches the same input as \texttt{a}.
\end{itemize}

In a lexical rule, a regular expression \texttt{r} may be preceded by a
\texttt{\^{}} (the beginning of line operator). \texttt{r} is then only
matched at the beginning of a line in the input. A line begins after
each occurrence of
\texttt{\textbackslash{}r\textbar{}\textbackslash{}n\textbar{}\textbackslash{}r\textbackslash{}n\textbar{}\textbackslash{}u2028\textbar{}\textbackslash{}u2029\textbar{}\textbackslash{}u000B\textbar{}\textbackslash{}u000C\textbar{}\textbackslash{}u0085}
(see also \autocite{unicode_rep}) and at the beginning of input. The
preceding line terminator in the input is not consumed and can be
matched by another rule.

In a lexical rule, a regular expression \texttt{r} may be followed by a
look-ahead expression. A look-ahead expression is either \texttt{\$}
(the end of line operator) or \texttt{/} followed by an arbitrary
regular expression. In both cases the look-ahead is not consumed and not
included in the matched text region, but it \textbf{is} considered while
determining which rule has the longest match (see also
\hyperref[HowMatched]{How the input is matched}).

In the \texttt{\$} case, \texttt{r} is only matched at the end of a line
in the input. The end of a line is denoted by the regular expression
\texttt{\textbackslash{}r\textbar{}\textbackslash{}n\textbar{}\textbackslash{}r\textbackslash{}n\textbar{}\textbackslash{}u2028\textbar{}\textbackslash{}u2029\textbar{}\textbackslash{}u000B\textbar{}\textbackslash{}u000C\textbar{}\textbackslash{}u0085}.
So \texttt{a\$} is equivalent to
\texttt{a\ /\ \textbackslash{}r\textbar{}\textbackslash{}n\textbar{}\textbackslash{}r\textbackslash{}n\textbar{}\textbackslash{}u2028\textbar{}\textbackslash{}u2029\textbar{}\textbackslash{}u000B\textbar{}\textbackslash{}u000C\textbar{}\textbackslash{}u0085}.
This is different to the situation described in \autocite{unicode_rep}:
since in JFlex \texttt{\$} is a true trailing context, the end of file
does \textbf{not} count as end of line.

For arbitrary look-ahead (also called \emph{trailing context}) the
expression is matched only when followed by input that matches the
trailing context.

JFlex allows lex/flex style
\texttt{\textless{}\textless{}EOF\textgreater{}\textgreater{}} rules in
lexical specifications. A rule

\begin{verbatim}
[StateList]  <<EOF>>    { action code }
\end{verbatim}

is very similar to the \texttt{\%eofval} directive. The difference lies
in the optional \texttt{StateList} that may precede the
\texttt{\textless{}\textless{}EOF\textgreater{}\textgreater{}} rule. The
action code will only be executed when the end of file is read and the
scanner is currently in one of the lexical states listed in
\texttt{StateList}. The same \texttt{StateGroup} (see section
\hyperref[HowMatched]{How the input is matched}) and precedence rules as
in the ``normal'' rule case apply (i.e.~if there is more than one
\texttt{\textless{}\textless{}EOF\textgreater{}\textgreater{}} rule for
a certain lexical state, the action of the one appearing earlier in the
specification will be executed).
\texttt{\textless{}\textless{}EOF\textgreater{}\textgreater{}} rules
override settings of the \texttt{\%cup} and \texttt{\%byaccj} options
and should not be mixed with the \texttt{\%eofval} directive.

An \texttt{Action} consists either of a piece of Java code enclosed in
curly braces or is the special \texttt{\textbar{}} action. The
\texttt{\textbar{}} action is an abbreviation for the action of the
following expression.

Example:

\begin{verbatim}
expression1   |
expression2   |
expression3   { some action }
\end{verbatim}

is equivalent to the expanded form

\begin{verbatim}
expression1   { some action }
expression2   { some action }
expression3   { some action }
\end{verbatim}

They are useful when working with trailing context expressions. The
expression \texttt{a\ \textbar{}\ (c\ /\ d)\ \textbar{}\ b} is not a
syntactically legal regular expression, but can be expressed using the
\texttt{\textbar{}} action:

\begin{verbatim}
a       |
c / d   |
b       { some action }
\end{verbatim}

\hyperdef{}{HowMatched}{\subsubsection{How the input is
matched}\label{HowMatched}}

When consuming its input, the scanner determines the regular expression
that matches the longest portion of the input (longest match rule). If
there is more than one regular expression that matches the longest
portion of input (i.e.~they all match the same input), the generated
scanner chooses the expression that appears first in the specification.
After determining the active regular expression, the associated action
is executed. If there is no matching regular expression, the scanner
terminates the program with an error message (if the
\texttt{\%standalone} directive has been used, the scanner prints the
unmatched input to \texttt{java.lang.System.out} instead and resumes
scanning).

Lexical states can be used to further restrict the set of regular
expressions that match the current input.

\begin{itemize}
\item
  A regular expression can only be matched when its associated set of
  lexical states includes the currently active lexical state of the
  scanner or if the set of associated lexical states is empty and the
  currently active lexical state is inclusive. Exclusive and inclusive
  states only differ in this one point: rules with an empty set of
  associated states.
\item
  The currently active lexical state of the scanner can be changed from
  within an action of a regular expression using the method
  \texttt{yybegin()}.
\item
  The scanner starts in the inclusive lexical state \texttt{YYINITIAL},
  which is always declared by default.
\item
  The set of lexical states associated with a regular expression is the
  \texttt{StateList} that precedes the expression. If a rule is
  contained in one or more \texttt{StateGroups}, then the states of
  these are also associated with the rule, i.e.~they accumulate over
  \texttt{StateGroups}.

  Example:

\begin{verbatim}
%states A, B
%xstates C
%%
expr1                   { yybegin(A); action }
<YYINITIAL, A> expr2    { action }
<A> {
  expr3                 { action }
  <B,C> expr4           { action }
}
\end{verbatim}

  The first line declares two (inclusive) lexical states \texttt{A} and
  \texttt{B}, the second line an exclusive lexical state \texttt{C}. The
  default (inclusive) state \texttt{YYINITIAL} is always implicitly
  there and doesn't need to be declared. The rule with \texttt{expr1}
  has no states listed, and is thus matched in all states but the
  exclusive ones, i.e.~\texttt{A}, \texttt{B}, and \texttt{YYINITIAL}.
  In its action, the scanner is switched to state \texttt{A}. The second
  rule \texttt{expr2} can only match when the scanner is in state
  \texttt{YYINITIAL} or \texttt{A}. The rule \texttt{expr3} can only be
  matched in state \texttt{A} and \texttt{expr4} in states \texttt{A},
  \texttt{B}, and \texttt{C}.
\item
  Lexical states are declared and used as Java \texttt{int} constants in
  the generated class under the same name as they are used in the
  specification. There is no guarantee that the values of these integer
  constants are distinct. They are pointers into the generated DFA
  table, and if JFlex recognises two states as lexically equivalent (if
  they are used with the exact same set of regular expressions), then
  the two constants will get the same value.
\end{itemize}

\subsubsection{The generated class}\label{the-generated-class}

JFlex generates exactly one file containing one class from the
specification (unless you have declared another class in the first
specification section).

The generated class contains (among other things) the DFA tables, an
input buffer, the lexical states of the specification, a constructor,
and the scanning method with the user supplied actions.

The name of the class is by default \texttt{Yylex}. The name is
customisable with the \texttt{\%class} directive. The input buffer of
the lexer is connected with external input through the
\texttt{java.io.Reader} object which is passed to the lexer in the
generated constructor. If you provide your own constructor for the
lexer, you should always chain-call the generated one to initialise the
input buffer. The input buffer should not be accessed directly, but only
through the advertised API (see also \hyperref[ScannerMethods]{Scanner
Methods}). Its internal implementation may change between releases or
skeleton files without notice.

The main interface to the outside world is the generated scanning method
(default name \texttt{yylex}, default return type \texttt{Yytoken}).
Most of its aspects are customisable (name, return type, declared
exceptions etc.). If it is called, it will consume input until one of
the expressions in the specification is matched or an error occurs. If
an expression is matched, the corresponding action is executed. It may
return a value of the specified return type (in which case the scanning
method returns with this value), or, if it does not return a value, the
scanner resumes consuming input until the next expression is matched. If
the end of file is reached, the scanner executes the \texttt{EOF}
action, and (also upon each further call to the scanning method) returns
the specified \texttt{EOF} value.

\hyperdef{}{ScannerMethods}{\subsubsection{Scanner methods and fields
accessible in actions (API)}\label{ScannerMethods}}

Generated methods and member fields in JFlex scanners are prefixed with
\texttt{yy} to indicate that they are generated and to avoid name
conflicts with user code copied into the class. Since user code is part
of the same class, JFlex has no language means like the \texttt{private}
modifier to indicate which members and methods are internal and which
ones belong to the API. Instead, JFlex follows a naming convention:
everything starting with \texttt{zz}, such as \texttt{zzStartRead}, is
internal and subject to change without notice between JFlex releases.
Methods and members of the generated class that do not have a
\texttt{zz} prefix, such as \texttt{yycharat}, belong to the API that
the scanner class provides to users in action code of the specification.
They will remain stable and supported between JFlex releases as long as
possible.

Currently, the API consists of the following methods and member fields:

\begin{itemize}
\item
  \texttt{String\ yytext()}

  returns the matched input text region
\item
  \texttt{int\ yylength()}

  returns the length of the matched input text region (does not require
  a \texttt{String} object to be created)
\item
  \texttt{char\ yycharat(int\ pos)}

  returns the character at position \texttt{pos} from the matched text.
  It is equivalent to \texttt{yytext().charAt(pos)}, but faster.
  \texttt{pos} must be a value from \texttt{0} to \texttt{yylength()-1}.
\item
  \texttt{void\ yyclose()}

  closes the input stream. All subsequent calls to the scanning method
  will return the end of file value
\item
  \texttt{void\ yyreset(java.io.Reader\ reader)}

  closes the current input stream, and resets the scanner to read from a
  new Reader. All internal variables are reset, the old Reader
  \emph{cannot} be reused (content of the internal buffer is discarded
  and lost). The lexical state is set to \texttt{YY\_INITIAL}. The
  \texttt{\%\{init} code is \emph{not} included in \texttt{yyreset},
  because it is assumed to run in the context of a constructor, not a
  normal method. If \texttt{\%\{init} does need to be repeated, consider
  constructing a new lexer object instead, or calling a custom function
  that performs any additional user-level state reset.
\item
  \texttt{void\ yypushStream(java.io.Reader\ reader)}

  Stores the current input stream on a stack, and reads from a new
  stream. Lexical state, line, char, and column counting remain
  untouched. The current input stream can be restored with
  \texttt{yypopStream} (usually in an
  \texttt{\textless{}\textless{}EOF\textgreater{}\textgreater{}}
  action).

  A typical example for this are include files in style of the C
  pre-processor. The corresponding JFlex specification could look like
  this:

\begin{verbatim}
"#include" {FILE}  { yypushStream(new FileReader(getFile(yytext()))); }
...
<<EOF>>            { if (yymoreStreams()) yypopStream(); else return EOF; }
\end{verbatim}

  This method is only available in the skeleton file
  \texttt{skeleton.nested}. You can find it in the \texttt{src}
  directory of the JFlex distribution.
\item
  \texttt{void\ yypopStream()}

  Closes the current input stream and continues to read from the one on
  top of the stream stack.

  This method is only available in the skeleton file
  \texttt{skeleton.nested}. You can find it in the \texttt{src}
  directory of the JFlex distribution.
\item
  \texttt{boolean\ yymoreStreams()}

  Returns true iff there are still streams for \texttt{yypopStream} left
  to read from on the stream stack.

  This method is only available in the skeleton file
  \texttt{skeleton.nested}. You can find it in the \texttt{src}
  directory of the JFlex distribution.
\item
  \texttt{int\ yystate()}

  returns the current lexical state of the scanner.
\item
  \texttt{void\ yybegin(int\ lexicalState)}

  enters the lexical state \texttt{lexicalState}
\item
  \texttt{void\ yypushback(int\ number)}

  pushes \texttt{number} characters of the matched text back into the
  input stream. They will be read again in the next call of the scanning
  method. The number of characters to be read again must not be greater
  than the length of the matched text. The pushed back characters will
  not be included in \texttt{yylength()} and \texttt{yytext()}. Note
  that in Java strings are unchangeable, i.e.~an action code like

\begin{verbatim}
    String matched = yytext();
    yypushback(1);
    return matched;
\end{verbatim}

  will return the whole matched text, while

\begin{verbatim}
    yypushback(1);
    return yytext();
\end{verbatim}

  will return the matched text minus the last character.
\item
  \texttt{int\ yyline}

  contains the current line of input (starting with 0, only active with
  the \texttt{lineCounting} directive)
\item
  \texttt{int\ yychar}

  contains the current character count in the input (starting with 0,
  only active with the \texttt{charCounting} directive)
\item
  \texttt{int\ yycolumn}

  contains the current column of the current line (starting with 0, only
  active with the \texttt{columnCounting} directive)
\end{itemize}

\hyperdef{}{sec:encodings}{\section{Encodings, Platforms, and
Unicode}\label{sec:encodings}}

This section discusses Unicode and encodings, cross platform scanning,
and how to deal with binary data.

\subsection{The Problem}\label{the-problem}

Java aims to be implementation platform independent, yet different
platforms use different ways to encode characters. Moreover, a file
written on one platform, say Windows, may later be read by a scanner on
another platform, for instance Linux.

If a program reads a file from disk, what it really reads is a stream of
bytes. These bytes can be mapped to characters in different ways. For
instance, in standard ASCII, the byte value 65 stands for the character
\texttt{A}, and in the encoding \texttt{iso-latin-1}, the byte value 213
stands for the umlaut character \texttt{ä}, but in the encoding
\texttt{iso-latin-2} the value 213 is \texttt{é} instead. As long as one
encoding is used consistently, this is no problem. Some characters may
not be available in the encoding you are using, but at least the
interpretation of the mapping between bytes and characters agrees
between different programs.

When your program runs on more than one platform, however, as is often
the case with Java, things become more complex. Java's solution to this
is to use Unicode internally. Unicode aims to be able to represent all
known character sets and is therefore a perfect base for encoding things
that might get used all over the world and on different platforms. To
make things work correctly, you still have to know where you are and how
to map byte values to Unicode characters and vice versa, but the
important thing is, that this mapping is at least possible (you can map
Kanji characters to Unicode, but you cannot map them to ASCII or
\texttt{iso-latin-1}).

\subsection{Scanning text files}\label{scanning-text-files}

Scanning text files is the standard application for scanners like JFlex.
Therefore it should also be the most convenient one. Most times it is.

The following scenario works fine: You work on a platform X, write your
lexer specification there, can use any obscure Unicode character in it
as you like, and compile the program. Your users work on any platform Y
(possibly but not necessarily something different from X), they write
their input files on Y and they run your program on Y. No problems.

Java does this as follows: If you want to read anything in Java that is
supposed to contain text, you use a \texttt{FileReader}, which converts
the bytes of the file into Unicode characters with the platform's
default encoding. If a text file is produced on the same platform, the
platform's default encoding should do the mapping correctly. Since JFlex
also uses readers and Unicode internally, this mechanism also works for
the scanner specifications. If you write an \texttt{A} in your text
editor and the editor uses the platform's encoding (say \texttt{A} is
65), then Java translates this into the logical Unicode \texttt{A}
internally. If a user writes an \texttt{A} on a completely different
platform (say \texttt{A} is 237 there), then Java also translates this
into the logical Unicode \texttt{A} internally. Scanning is performed
after that translation and both match.

Note that because of this mapping from bytes to characters, you should
always use the \texttt{\%unicode} switch in you lexer specification if
you want to scan text files. \texttt{\%8bit} may not be enough, even if
you know that your platform only uses one byte per character. The
encoding \texttt{Cp1252} used on many Windows machines for instance
knows 256 characters, but the character \texttt{\textquotesingle{}} with
\texttt{Cp1252} code \texttt{\textbackslash{}x92} has the Unicode value
\texttt{\textbackslash{}u2019}, which is larger than 255 and which would
make your scanner throw an \texttt{ArrayIndexOutOfBoundsException} if it
is encountered.

So for the usual case you don't have to do anything but use the
\texttt{\%unicode} switch in your lexer specification.

Things may break when you produce a text file on platform X and consume
it on a different platform Y. Let's say you have a file written on a
Windows PC using the encoding \texttt{Cp1252}. Then you move this file
to a Linux PC with encoding \texttt{ISO\ 8859-1} and there you run your
scanner on it. Java now thinks the file is encoded in
\texttt{ISO\ 8859-1} (the platform's default encoding) while it really
is encoded in \texttt{Cp1252}. For most characters \texttt{Cp1252} and
\texttt{ISO\ 8859-1} are the same, but for the byte values
\texttt{\textbackslash{}x80} to \texttt{\textbackslash{}x9f} they
disagree: \texttt{ISO\ 8859-1} is undefined there. You can fix the
problem by telling Java explicitly which encoding to use. When
constructing the \texttt{InputStreamReader}, you can give the encoding
as argument. The line

\begin{verbatim}
Reader r = new InputStreamReader(input, Cp1252);
\end{verbatim}

will do the trick.

Of course the encoding to use can also come from the data itself: for
instance, when you scan an HTML page, it may have embedded information
about its character encoding in the headers.

More information about encodings, which ones are supported, how they are
called, and how to set them may be found in the official Java
documentation in the chapter about internationalisation. The link
\url{http://docs.oracle.com/javase/1.5.0/docs/guide/intl/} leads to an
online version of this for Oracle's JDK 1.5.

\subsection{Scanning binaries}\label{scanning-binaries}

Scanning binaries is both easier and more difficult than scanning text
files. It's easier because you want the raw bytes and not their meaning,
i.e.~you don't want any translation. It's more difficult because it's
not so easy to get ``no translation'' when you use Java readers.

The problem (for binaries) is that JFlex scanners are designed to work
on text. Therefore the interface is the \texttt{Reader} class. You can
still get a binary scanner when you write your own custom
\texttt{InputStreamReader} class that explicitly does no translation,
but just copies byte values to character codes instead. It sounds quite
easy, and actually it is no big deal, but there are a few pitfalls on
the way. In the scanner specification you can only enter positive
character codes (for bytes that is \texttt{\textbackslash{}x00} to
\texttt{\textbackslash{}xFF}). Java's \texttt{byte} type on the other
hand is a signed 8 bit integer (-128 to 127), so you have to convert
them accordingly in your custom \texttt{Reader}. Also, you should take
care when you write your lexer spec: if you use text in there, it gets
interpreted by an encoding first, and what scanner you get as result
might depend on which platform you run JFlex on when you generate the
scanner (this is what you want for text, but for binaries it gets in the
way). If you are not sure, or if the development platform might change,
it's probably best to use character code escapes in all places, since
they don't change their meaning.

\hyperdef{}{unicoderegexconformance}{\section{Conformance with Unicode
Regular Expressions UTS\#18}\label{unicoderegexconformance}}

This section gives details about JFlex 1.7.0-SNAPSHOT's conformance with
the requirements for Basic Unicode Support Level 1 given in UTS\#18
\autocite{unicode_rep}.

\subsubsection{RL1.1 Hex Notation}\label{rl1.1-hex-notation}

\begin{quote}
\emph{To meet this requirement, an implementation shall supply a
mechanism for specifying any Unicode code point (from U+0000 to
U+10FFFF), using the hexadecimal code point representation.}
\end{quote}

JFlex conforms. Syntax is provided to express values across the whole
range, via \texttt{\textbackslash{}uXXXX}, where \texttt{XXXX} is a
4-digit hex value; \texttt{\textbackslash{}Uyyyyyy}, where
\texttt{yyyyyy} is a 6-digit hex value; and
\texttt{\textbackslash{}u\{X+(\ X+)*\}}, where \texttt{X+} is a 1-6
digit hex value.

\subsubsection{RL1.2 Properties}\label{rl1.2-properties}

\begin{quote}
\emph{To meet this requirement, an implementation shall provide at least
a minimal list of properties, consisting of the following:
General\_Category, Script and Script\_Extensions, Alphabetic, Uppercase,
Lowercase, White\_Space, Noncharacter\_Code\_Point,
Default\_Ignorable\_Code\_Point, ANY, ASCII, ASSIGNED.}

\emph{The values for these properties must follow the Unicode
definitions, and include the property and property value aliases from
the UCD. Matching of Binary, Enumerated, Catalog, and Name values, must
follow the Matching Rules from {[}UAX44{]}.}
\end{quote}

JFlex conforms. The minimal set of properties is supported, as well as a
few others. To see the full list of supported properties, use the JFlex
command line option \texttt{-\/-uniprops\ \textless{}ver\textgreater{}},
where \texttt{\textless{}ver\textgreater{}} is the Unicode version.
Loose matching is performed: case distinctions, whitespace, underscores
and hyphens in property names and values are ignored.

\subsubsection{RL1.2a Compatibility
Properties}\label{rl1.2a-compatibility-properties}

\begin{quote}
\emph{To meet this requirement, an implementation shall provide the
properties listed in Annex C: Compatibility Properties, with the
property values as listed there. Such an implementation shall document
whether it is using the Standard Recommendation or POSIX-compatible
properties.}
\end{quote}

JFlex does not fully conform. The Standard Recommendation version of the
Annex C Compatibility Properties are provided, with two exceptions:
\texttt{\textbackslash{}X} Extended Grapheme Clusters; and
\texttt{\textbackslash{}b} Default Word Boundaries.

\subsubsection{RL1.3 Subtraction and
Intersection}\label{rl1.3-subtraction-and-intersection}

\begin{quote}
\emph{To meet this requirement, an implementation shall supply
mechanisms for union, intersection and set-difference of Unicode sets.}
\end{quote}

JFlex conforms by providing these mechanisms, as well as symmetric
difference.

\subsubsection{RL1.4 Simple Word
Boundaries}\label{rl1.4-simple-word-boundaries}

\begin{quote}
\emph{To meet this requirement, an implementation shall extend the word
boundary mechanism so that:}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \emph{The class of \texttt{\textless{}word\_character\textgreater{}}
  includes all the Alphabetic values from the Unicode character
  database, from UnicodeData.txt {[}UData{]}, plus the decimals
  (General\_Category=Decimal\_Number, or equivalently
  Numeric\_Type=Decimal), and the U+200C ZERO WIDTH NON-JOINER and
  U+200D ZERO WIDTH JOINER (Join\_Control=True). See also Annex C:
  Compatibility Properties.}
\item
  \emph{Nonspacing marks are never divided from their base characters,
  and otherwise ignored in locating boundaries.}
\end{enumerate}
\end{quote}

JFlex does not conform: \texttt{\textbackslash{}b} does not match simple
word boundaries.

\subsubsection{RL1.5 Simple Loose
Matches}\label{rl1.5-simple-loose-matches}

\begin{quote}
\emph{To meet this requirement, if an implementation provides for
case-insensitive matching, then it shall provide at least the simple,
default Unicode case-insensitive matching, and specify which properties
are closed and which are not.}

\emph{To meet this requirement, if an implementation provides for case
conversions, then it shall provide at least the simple, default Unicode
case folding.}
\end{quote}

JFlex conforms. All supported Unicode Properties are closed.

\subsubsection{RL1.6 Line Boundaries}\label{rl1.6-line-boundaries}

\begin{quote}
\emph{To meet this requirement, if an implementation provides for
line-boundary testing, it shall recognize not only CRLF, LF, CR, but
also NEL (U+0085), PARAGRAPH SEPARATOR (U+2029) and LINE SEPARATOR
(U+2028).}
\end{quote}

JFlex conforms.

\subsubsection{RL1.7 Supplementary Code
Points}\label{rl1.7-supplementary-code-points}

\begin{quote}
\emph{To meet this requirement, an implementation shall handle the full
range of Unicode code points, including values from U+FFFF to U+10FFFF.
In particular, where UTF-16 is used, a sequence consisting of a leading
surrogate followed by a trailing surrogate shall be handled as a single
code point in matching.}
\end{quote}

JFlex conforms.

\hyperdef{}{performance}{\section{A few words on
performance}\label{performance}}

This section gives tips on how to make your specification produce a
faster scanner.

In general, the regular expression matching generated by JFlex has very
good performance. It is DFA-based (deterministic finite automata) and
does not require backtracking over alternative as for instance
perl-style regular expression matching does. In the optimal case, each
character is only examined once, in some situations explained below, a
small amount of backtracking is necessary to determine the longest
match.

Even within the class of DFA-based scanners, JFlex generated scanners
usually show very good performance without special optimisations. The
following lists a few heuristics that can make a lexical specification
produce an even faster scanner. Those are (roughly in order of
performance gain):

\begin{itemize}
\item
  Avoid rules that require backtracking

  While there is no backtracking for expressions like
  \texttt{a\textbar{}b} in JFlex, some backtracking is still introduced
  by the longest match rule and occurs for instance on this set of
  expressions:

\begin{verbatim}
averylongkeyword
.
\end{verbatim}

  With input \texttt{averylongjoke} the scanner has to read all
  characters up to \texttt{’j’} to decide that rule \texttt{.} should be
  matched. All characters of \texttt{verylong} have to be read again for
  the next matching process.

  From the C/C++ flex \autocite{flex} man page: \emph{Getting rid of
  backtracking is messy and often may be an enormous amount of work for
  a complicated scanner.} Backtracking can be avoided in general by
  adding error rules that match those error conditions

\begin{verbatim}
"av"|"ave"|"avery"|"averyl"|..
\end{verbatim}

  While this is impractical in most scanners, there is still the
  possibility to add a \emph{catch all} rule for a lengthy list of
  keywords

\begin{verbatim}
"keyword1"  { return symbol(KEYWORD1); } 
.. 
"keywordn"  { return symbol(KEYWORDn); }
[a-z]+      { error("not a keyword"); }
\end{verbatim}

  Most programming language scanners already have a rule like this for
  some kind of variable length identifiers, which means this kind of
  backtracking for programming language scanners often concerns only at
  most a single character.
\item
  Avoid line and column counting

  It costs multiple additional comparisons per input character and the
  matched text has to be re-scanned for counting. In most scanners it is
  possible to do the line counting in the specification by incrementing
  \texttt{yyline} each time a line terminator has been matched. Column
  counting could also be included in actions. This will be faster, but
  can in some cases become quite messy.
\item
  Avoid look-ahead expressions and the end of line operator '\$'

  In the best case, the trailing context will first have to be read and
  then (because it is not to be consumed) re-read again. The cases of
  fixed-length look-ahead and fixed-length base expressions are handled
  efficiently by matching the concatenation and then pushing back the
  required amount of characters. This extends to the case of a
  disjunction of fixed-length look-ahead expressions such as
  \texttt{r1\ /\ \textbackslash{}r\textbar{}\textbackslash{}n\textbar{}\textbackslash{}r\textbackslash{}n}.
  All other cases \texttt{r1\ /\ r2} are handled by first scanning the
  concatenation of \texttt{r1} and \texttt{r2}, and then finding the
  correct end of \texttt{r1}. The end of \texttt{r1} is found by
  scanning forwards in the match again, marking all possible \texttt{r1}
  terminations, and then scanning the reverse of \texttt{r2} backwards
  from the end until a start of \texttt{r2} intersects with an end of
  \texttt{r1}. This algorithm is linear in the size of the input (not
  quadratic or worse as backtracking is), but about a factor of 2 slower
  than normal scanning. It also consumes memory proportional to the size
  of the matched input for \texttt{r1\ r2}.
\item
  Avoid the beginning of line operator '\texttt{\^{}}'

  It costs multiple additional comparisons per match. In some cases one
  extra look-ahead character is needed (when the last character read is
  \texttt{\textbackslash{}r}, the scanner has to read one character
  ahead to check if the next one is an \texttt{\textbackslash{}n} or
  not).
\item
  Match as much text as possible in a rule.

  One rule is matched in the innermost loop of the scanner. After each
  action, setting up the internal state of the scanner is necessary and
  induces a small overhead.
\end{itemize}

Note that writing more rules in a specification does \emph{not} make the
generated scanner slower.

The two main rules of optimisation apply also for lexical
specifications:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\itemsep1pt\parskip0pt\parsep0pt
\item
  \textbf{don't do it}
\item
  \textbf{(for experts only) don't do it yet}
\end{enumerate}

Some of the performance tips above contradict a readable and compact
specification style. When in doubt or when requirements are not or not
yet fixed: don't use them --- the specification can always be optimised
in a later state of the development process.

\hyperdef{}{Porting}{\section{Porting Issues}\label{Porting}}

\subsection{Porting from JLex}\label{porting-from-jlex}

JFlex was designed to read old JLex specifications unchanged and to
generate a scanner which behaves exactly the same as the one generated
by JLex with the only difference of being faster.

This works as expected on all well formed JLex specifications.

Since the statement above is somewhat absolute, let's take a look at
what \emph{well formed} means for this purpose. A JLex specification is
well formed, when it

\begin{itemize}
\item
  generates a working scanner with JLex
\item
  doesn't contain the unescaped characters \texttt{!} and
  \texttt{\textasciitilde{}}

  They are operators in JFlex while JLex treats them as normal input
  characters. You can easily port such a JLex specification to JFlex by
  replacing every \texttt{!} with \texttt{\textbackslash{}!} and every
  \texttt{\textasciitilde{}} with
  \texttt{\textbackslash{}\textasciitilde{}} in all regular expressions.
\item
  has only complete regular expressions surrounded by parentheses in
  macro definitions

  This may sound a bit harsh, but is usually not a big problem -- it can
  also help you find some disgusting bugs in your specification that
  went unnoticed so far. In JLex, the right hand side of a macro is just
  a piece of text that is copied to the point where the macro is used.
  With this, things like

\begin{verbatim}
  macro1 = ("hello"
  macro2 = {macro1})*
\end{verbatim}

  were possible (with \texttt{macro2} expanding to \texttt{("hello")*}).
  This is not allowed in JFlex and you will have to transform such
  definitions. There are more subtle kinds of errors that can be
  introduced by JLex macros. Consider a definition such as
  \texttt{macro\ =\ a\textbar{}b} and a usage like \texttt{\{macro\}*}.
  This expands in JLex to \texttt{a\textbar{}b*} and not to the probably
  intended \texttt{(a\textbar{}b)*}.

  Basically, JLex uses C-preprocessor style macros, whereas JFlex uses
  grammar definitions.

  Most specifications shouldn't suffer from this problem, because macros
  often only contain (harmless) character classes like
  \texttt{alpha\ =\ {[}a-zA-Z{]}} and more dangerous definitions like

  \texttt{ident\ =\ \{alpha\}(\{alpha\}\textbar{}\{digit\})*}

  are only used to write rules like

  \texttt{\{ident\}\ \ \ \ \ \ \ \{\ ..\ action\ ..\ \}}

  and not more complex expressions like

  \texttt{\{ident\}*\ \ \ \ \ \ \{\ ..\ action\ ..\ \}}

  where the kind of error presented above would show up.
\end{itemize}

\subsection{Porting from lex/flex}\label{porting-from-lexflex}

This section gives an incomplete overview of potential pitfalls and
steps for porting a lexical specification from the C/C++ tools
\texttt{lex} and \texttt{flex} \autocite{flex} available on most Unix
systems to JFlex.

Most of the C/C++ specific features are naturally not present in JFlex,
but most ``clean'' lex/flex lexical specifications can be ported to
JFlex without too much work.

\subsubsection{Basic structure}\label{basic-structure}

A lexical specification for flex has the following basic structure:

\begin{verbatim}
definitions
%%
rules
%%
user code
\end{verbatim}

The \texttt{user\ code} section usually contains C code that is used in
actions of the \texttt{rules} part of the specification. For JFlex, this
code will have to be translated to Java, and most of it will then go
into the class code \texttt{\%\{..\%\}} directive in the
\texttt{options\ and\ declarations} section.

\subsubsection{Macros and Regular Expression
Syntax}\label{macros-and-regular-expression-syntax}

The \texttt{definitions} section of a flex specification is quite
similar to the \texttt{options\ and\ declarations} part of JFlex specs.

Macro definitions in flex have the form:

\begin{verbatim}
<identifier>  <expression>
\end{verbatim}

To port them to JFlex macros, just insert a \texttt{=} between
\texttt{\textless{}identifier\textgreater{}} and
\texttt{\textless{}expression\textgreater{}}.

The syntax and semantics of regular expressions in flex are pretty much
the same as in JFlex. Some attention is needed for escape sequences
present in flex (such as \texttt{\textbackslash{}a}) that are not
supported in JFlex. These escape sequences should be transformed into
their unicode equivalent.

\subsubsection{Character Classes}\label{character-classes}

Flex offers the character classes directly supported by C, JFlex offers
the ones supported by Java. These classes will sometimes have to be
listed manually.

In flex more special characters lose their meaning in character classes.
In particular\footnote{Thanks to Dimitri Maziuk for pointing these out.}:

\begin{itemize}
\item
  in flex \texttt{{[}{]}{[}{]}} is the character class containing
  \texttt{{]}} and \texttt{{[}}, whereas in JFlex, the expression means
  ``empty expression'' followed by ``empty expression''. To get
  \texttt{{]}} and \texttt{{[}} in JFlex, use for instance
  \texttt{{[}\textbackslash{}{]}\textbackslash{}{[}{]}}.
\item
  the classes \texttt{{[}{]}} and \texttt{{[}\^{}{]}} are illegal in
  flex, but have meaning in JFlex.
\item
  in flex \texttt{{[}"{]}} is legal, in JFlex you need
  \texttt{{[}\textbackslash{}"{]}}.
\end{itemize}

\subsubsection{Lexical Rules}\label{lexical-rules}

Since flex is mostly Unix based, the '\texttt{\^{}}' (beginning of line)
and '\texttt{\$}' (end of line) operators, consider the
\texttt{\textbackslash{}n} character as only line terminator. This
should usually not cause much problems, but you should be prepared for
occurrences of \texttt{\textbackslash{}r} or
\texttt{\textbackslash{}r\textbackslash{}n} or one of the characters
\texttt{\textbackslash{}u2028}, \texttt{\textbackslash{}u2029},
\texttt{\textbackslash{}u000B}, \texttt{\textbackslash{}u000C}, or
\texttt{\textbackslash{}u0085}. They are considered to be line
terminators in Unicode and therefore may not be consumed when
\texttt{\^{}} or \texttt{\$} is present in a rule.

\hyperdef{}{WorkingTog}{\section{Working together}\label{WorkingTog}}

\hyperdef{}{CUPWork}{\subsection{JFlex and CUP}\label{CUPWork}}

One of the design goals of JFlex was to make interfacing with the parser
generators CUP \autocite{CUP} and CUP2 \autocite{CUP2} as easy as
possible. This has been done by providing the \texttt{\%cup} and
\texttt{\%cup2} directives in JFlex. However, each interface has two
sides. This section concentrates on the CUP side of the story.

\subsubsection{CUP2}\label{cup2}

Please refer to the CUP2 \autocite{CUP2} documentation, which provides
instructions on how to interface with JFlex. The CUP2 JFlex patch
provided there is not necessary any more for JFlex versions greater than
1.5.0.

\subsubsection{CUP version 0.10j and
above}\label{cup-version-0.10j-and-above}

Since CUP version 0.10j, interfacing with JFlex has been simplified
greatly by the new CUP scanner interface
\texttt{java\_cup.runtime.Scanner}. JFlex lexers now implement this
interface automatically when the \texttt{\%cup} switch is used. There
are no special \texttt{parser\ code}, \texttt{init\ code} or
\texttt{scan\ with} options any more that you have to provide in your
CUP parser specification. You can just concentrate on your grammar.

If your generated lexer has the class name \texttt{Scanner}, the parser
is started from the main program like this:

\begin{verbatim}
...
  try {
    parser p = new parser(new Scanner(new FileReader(fileName)));
    Object result = p.parse().value;
  }
  catch (Exception e) {
...
\end{verbatim}

\subsubsection{Custom symbol interface}\label{custom-symbol-interface}

If you have used the \texttt{-symbol} command line switch of CUP to
change the name of the generated symbol interface, you have to tell
JFlex about this change of interface so that correct end-of-file code is
generated. You can do so either by using an \texttt{\%eofval\{}
directive or by using an
\texttt{\textless{}\textless{}EOF\textgreater{}\textgreater{}} rule.

If your new symbol interface is called \texttt{mysym} for example, the
corresponding code in the jflex specification would be either

\begin{verbatim}
%eofval{
  return mysym.EOF;
%eofval}
\end{verbatim}

in the macro/directives section of the spec, or it would be

\begin{verbatim}
  <<EOF>>  { return mysym.EOF; }
\end{verbatim}

in the rules section of your spec.

\subsubsection{Using existing JFlex/CUP specifications with CUP 0.10j
and
above}\label{using-existing-jflexcup-specifications-with-cup-0.10j-and-above}

If you already have an existing specification and you would like to
upgrade both JFlex and CUP to their newest version, you will probably
have to adjust your specification.

The main difference between the \texttt{\%cup} switch in JFlex 1.2.1 and
lower, and more recent versions is that JFlex scanners now automatically
implement the \texttt{java\_cup.runtime.Scanner} interface. This means
the scanning function changes its name from \texttt{yylex()} to
\texttt{next\_token()}.

The main difference from older CUP versions to 0.10j is, that CUP now
has a default constructor that accepts a
\texttt{java\_cup.runtime.Scanner} as argument and that uses this
scanner as default (so no \texttt{scan\ with} code is necessary any
more).

If you have an existing CUP specification, it will probably look
somewhat like this:

\begin{verbatim}
parser code {:
  Lexer lexer;

  public parser (java.io.Reader input) {
    lexer = new Lexer(input);
  }
:};

scan with {: return lexer.yylex(); :};
\end{verbatim}

To upgrade to CUP 0.10j, you could change it to look like this:

\begin{verbatim}
parser code {:
  public parser (java.io.Reader input) {
    super(new Lexer(input));
  }
:};
\end{verbatim}

If you don't mind changing the method that is calling the parser, you
could remove the constructor entirely (and if there is nothing else in
it, the whole \texttt{parser\ code} section). The main method calling
the parser would then construct the parser as shown in the section
above.

The JFlex specification does not need to be changed.

\hyperdef{}{BYaccJ}{\subsection{JFlex and BYacc/J}\label{BYaccJ}}

JFlex has built-in support for the Java extension
\href{http://byaccj.sourceforge.net/}{BYacc/J} \autocite{BYaccJ} by Bob
Jamison to the classical Berkeley Yacc parser generator. This section
describes how to interface BYacc/J with JFlex. It builds on many helpful
suggestions and comments from Larry Bell.

Since Yacc's architecture is a bit different from CUP's, the interface
setup also works in a slightly different manner. BYacc/J expects a
function \texttt{int\ yylex()} in the parser class that returns each
next token. Semantic values are expected in a field \texttt{yylval} of
type \texttt{parserval} where \texttt{parser} is the name of the
generated parser class.

For a small calculator example, one could use a setup like the following
on the JFlex side:

\begin{verbatim}
%%

%byaccj

%{
  /* store a reference to the parser object */
  private parser yyparser;

  /* constructor taking an additional parser object */
  public Yylex(java.io.Reader r, parser yyparser) {
    this(r);
    this.yyparser = yyparser;
  }
%}

NUM = [0-9]+ ("." [0-9]+)?
NL  = \n | \r | \r\n

%%

/* operators */
"+" | 
..
"(" | 
")"    { return (int) yycharat(0); }

/* newline */
{NL}   { return parser.NL; }

/* float */
{NUM}  { yyparser.yylval = new parserval(Double.parseDouble(yytext()));
         return parser.NUM; }
\end{verbatim}

The lexer expects a reference to the parser in its constructor. Since
Yacc allows direct use of terminal characters like \texttt{’+’} in its
specifications, we just return the character code for single char
matches (e.g.~the operators in the example). Symbolic token names are
stored as \texttt{public\ static\ int} constants in the generated parser
class. They are used as in the \texttt{NL} token above. Finally, for
some tokens, a semantic value may have to be communicated to the parser.
The \texttt{NUM} rule demonstrates how.

A matching BYacc/J parser specification would look like this:

\begin{verbatim}
%{
  import java.io.*;
%}
      
%token NL          /* newline  */
%token <dval> NUM  /* a number */

%type <dval> exp

%left '-' '+'
..
%right '^'         /* exponentiation */
      
%%

..
      
exp:     NUM          { $$ = $1; }
       | exp '+' exp  { $$ = $1 + $3; }
       ..
       | exp '^' exp  { $$ = Math.pow($1, $3); }
       | '(' exp ')'  { $$ = $2; }
       ;

%%
  /* a reference to the lexer object */
  private Yylex lexer;

  /* interface to the lexer */
  private int yylex () {
    int yyl_return = -1;
    try {
      yyl_return = lexer.yylex();
    }
    catch (IOException e) {
      System.err.println("IO error :"+e);
    }
    return yyl_return;
  }

  /* error reporting */
  public void yyerror (String error) {
    System.err.println ("Error: " + error);
  }

  /* lexer is created in the constructor */
  public parser(Reader r) {
    lexer = new Yylex(r, this);
  }

  /* that's how you use the parser */
  public static void main(String args[]) throws IOException {
    parser yyparser = new parser(new FileReader(args[0]));
    yyparser.yyparse();    
  }
\end{verbatim}

Here, the customised part is mostly in the user code section. We create
the lexer in the constructor of the parser and store a reference to it
for later use in the parser's \texttt{int\ yylex()} method. This
\texttt{yylex} in the parser only calls \texttt{int\ yylex()} of the
generated lexer and passes the result on. If something goes wrong, it
returns -1 to indicate an error.

Runnable versions of the specifications above are located in the
\texttt{examples/byaccj} directory of the JFlex distribution.

\subsection{JFlex and Jay}\label{jflex-and-jay}

Combining JFlex with the
\href{http://www.cs.rit.edu/~ats/projects/lp/doc/jay/package-summary.html}{Jay
Parser Generator} \autocite{Jay} is quite simple. The Jay Parser
Generator defines an interface called
\texttt{\textless{}parsername\textgreater{}.yyInput}. In the JFlex
source the directive

\begin{verbatim}
%implements <parsername>.yyInput
\end{verbatim}

tells JFlex to generate the corresponding class declaration.

The three interface methods to implement are

\begin{itemize}
\item
  \texttt{advance()} which should return a boolean that is \texttt{true}
  if there is more work to do and \texttt{false} if the end of input has
  been reached,
\item
  \texttt{token()} which returns the last scanned token, and
\item
  \texttt{value()} which returns an Object that contains the (optional)
  value of the last read token.
\end{itemize}

The following shows a small example with Jay parser specification and
corresponding JFlex code. First of all the Jay code (in a file
\texttt{MiniParser.jay}):

\begin{verbatim}
%{
//
// Prefix Code like Package declaration, 
// imports, variables and the parser class declaration
// 

import java.io.*;
import java.util.*;

public class MiniParser 
{

%}

// Token declarations, and types of non-terminals

%token DASH COLON
%token <Integer> NUMBER

%token <String> NAME

%type <Gameresult> game
%type <Vector<Gameresult>> gamelist

// start symbol
%start gamelist

%%

gamelist: game        { $$ = new Vector<Gameresult>();
                        $<Vector<Gameresult>>$.add($1);
                      }
  |  gamelist game    { $1.add($2); }

game: NAME DASH NAME NUMBER COLON NUMBER {
      $$ = new Gameresult($1, $3, $4, $6); }

%%

  // supporting methods part of the parser class
  public static void main(String argv[])
  {
    MiniScanner scanner = new MiniScanner(new InputStreamReader(System.in));
    MiniParser parser = new MiniParser();
    try {
      parser.yyparse (scanner);
    } catch (final IOException ioe) {
      System.out.println("I/O Exception : " + ioe.toString());
    } catch (final MiniParser.yyException ye) {
      System.out.println ("Oops : " + ye.toString());
    }
  }

} // closing brace for the parser class

class Gameresult {
  String homeTeam;
  String outTeam;
  Integer homeScore;
  Integer outScore;

  public Gameresult(String ht, String ot, Integer hs, Integer os)
  {
    homeTeam = ht;
    outTeam = ot;
    homeScore = hs;
    outScore = os;
  }
}
\end{verbatim}

The corresponding JFlex code (MiniScanner.jflex) could be

\begin{verbatim}
%%

%public
%class MiniScanner
%implements MiniParser.yyInput
%integer

%line
%column
%unicode

%{
private int token;
private Object value;

// the next 3 methods are required to implement the yyInput interface

public boolean advance() throws java.io.IOException {
  value = new String("");
  token = yylex();
  return (token != YYEOF);
}

public int token() {
  return token;
}

public Object value() {
  return value;
}

%}

nl =     [\n\r]+
ws =     [ \t\b\015]+
number = [0-9]+
name =   [a-zA-Z]+
dash =   "-"
colon =  ":"

%%

{nl}      { /* do nothing */ }
{ws}      { /* happy meal */ }
{name}    { value = yytext(); return MiniParser.NAME; }
{dash}    { return MiniParser.DASH; }
{colon}   { return MiniParser.COLON; }
{number}  { try  {
              value = new Integer(Integer.parseInt(yytext()));
            } catch (NumberFormatException nfe) {
              // shouldn't happen
              throw new Error();
            }
            return MiniParser.NUMBER;
          }
\end{verbatim}

This small example reads an input like

\begin{verbatim}
Borussia - Schalke 3:2
ACMilano - Juventus 1:4
\end{verbatim}

\section{Bugs and Deficiencies}\label{Bugs}

\subsection{Deficiencies}\label{deficiencies}

JFlex 1.7.0-SNAPSHOT conforms with Unicode Regular Expressions UTS\#18
\autocite{unicode_rep} Basic Unicode Support Level 1, with a few
exceptions - for details see \hyperref[unicoderegexconformance]{UTS \#
18 Conformance}.

\subsection{Bugs}\label{bugs}

As of 16 March 2015, no major open problems are known for JFlex version
1.7.0-SNAPSHOT.

Please use the JFlex
\href{https://github.com/jflex-de/jflex/labels/bug}{github issue
tracker} for any problems that have been reported since then.

\section{Copying and License}\label{Copyright}

JFlex is free software, published under a BSD-style license.

There is \textbf{NO WARRANTY} for JFlex, its code and its documentation.

See the file \href{COPYRIGHT}{\texttt{COPYRIGHT}} for more information.
